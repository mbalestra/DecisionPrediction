{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "from ipynb.fs.full.GenerateData import generatedata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0) Define variables**\n",
    "\n",
    "$ \\{x_{1}, x_{2},...x_{k}\\} \\in X$, Observed features of defendant\n",
    " \n",
    "$\\mu_{prior}$, Judge's mean prior belief about a defendant; \\textit{most probable} risk prediction\n",
    "\n",
    "$\\sigma_{prior}$, Standard deviation of judge's prior belief on a defendant; corresponds to a judge's $\\textit{uncertainty}$ about prediction\n",
    "\n",
    "$\\mu_{ra}$, Observed algorithmic risk assessment prediction; mean of normally-distributed perceived anchor information\n",
    "\n",
    "$\\sigma_{ra}$, Perceived anchor $\\textit{influence}$; Corresponds to S.D. of risk assessment (when perceived as containing a lot of information S.D. will be lower and vice versa).\n",
    "\n",
    "$w,c$, Parameters for mapping $\\sigma_{prior}$ onto $\\sigma_{ra}$\n",
    "\n",
    "$z_{\\alpha}$, $z$-score distance between $\\mu_{prior}$ and $\\mu_{ra}$\n",
    "\n",
    "$z$, Threshold distance between $\\mu_{prior}$ and $\\mu_{ra}$ after which $\\mu_{ra}$ has no (or minimal) effect on $\\mu_{prior}$\n",
    "\n",
    "$\\mu_{post}$, Judge's mean posterior belief\n",
    "\n",
    "$\\sigma_{post}$, Standard deviation of judge's posterior belief \n",
    "\n",
    "$\\tau$, Decision making threshold\n",
    "\n",
    "$\\phi_{prior}(\\mu_{prior},\\sigma_{prior})$, Gaussian distribution representing judge's prior belief\n",
    "\n",
    "$\\phi_{ra}(\\mu_{ra},\\sigma_{ra})$, Gaussian distribution representing the influence of algorithmic risk assessment predictions\n",
    "\n",
    "$\\phi_{post}(\\mu_{post},\\sigma_{post})$, Gaussian distribution representing the judge's posterior belief\n",
    "\n",
    "$\\Phi_{post}$, Probability of drawing a belief from the posterior greater than threshold $\\tau$\n",
    "\n",
    "$y$, Judge's observed decision on defendant\n",
    " \n",
    "$\\alpha$, Learning rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Initialization functions**\n",
    "\n",
    "**(a) Parameters**\n",
    "\n",
    "$\\beta_{1}$ (nx1), $\\beta_{2}$ (nx1), $var_{prior} = \\sigma_{prior}^2$ (1x1), and $w$ (1x1) are randomly initialized (>0);\n",
    "$b$ (1x1) and $c$ (1x1) are initialized as zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(X,lower,upper):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    X -- training data\n",
    "    lower -- lower bound of scale\n",
    "    upper -- upper bound of scale\n",
    "    \n",
    "    Returns:\n",
    "    params -- python dictionary containing model parameters:\n",
    "        B -- coefficient matrix\n",
    "        b -- constant\n",
    "        q -- constant\n",
    "        mu_var -- variance of prior \n",
    "    \"\"\"\n",
    "    \n",
    "    #np.random.seed(212) \n",
    "    \n",
    "    # of parameters\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    B = np.random.rand(n,1)*0.1 # randomly initialize the B_0, B_1 coefficients\n",
    "    b = 0 # intialize  constants b,c @ 0\n",
    "    q = np.random.rand(1)\n",
    "    var = np.random.rand(1)*10\n",
    "    tau = random.randint(lower, upper)\n",
    "    \n",
    "    parameters = {\"B\": B,\n",
    "                  \"b\": b,\n",
    "                  \"q\" : q,\n",
    "                  \"var_prior\" : var,\n",
    "                  \"tau\" : tau}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary to store derivatives\n",
    "def initialize_dicts():\n",
    "    derivatives = {\n",
    "        \"dL\": [],\n",
    "        \"dL_dmuprior\": [],\n",
    "        \"dphipost_dmupost\": [],\n",
    "        \"dphipost_dvarpost\": [],\n",
    "        \"dphipost_dtau\": [],\n",
    "        \"dmupost_dmuprior\": [],\n",
    "        \"dvarpost_dq\": [],\n",
    "        \"dmupost_dq\": [],\n",
    "        \"dvarpost_dvarprior\": []\n",
    "    }\n",
    "\n",
    "    grads = {\n",
    "        \"dB\":[],\n",
    "        \"db\":[],\n",
    "        \"dvar_dprior\":[],\n",
    "        \"dq\":[],\n",
    "        \"dtau\":[]\n",
    "    }\n",
    "    \n",
    "    return derivatives,grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Forward**\n",
    "\n",
    "**(a) Estimate mean of prior belief distribution**\n",
    "\n",
    "Given {$\\beta, b, \\sigma, \\theta, \\tau, w$}, want to calculate loss, $\\mathcal{L}(\\hat{y},y_i)$ using the following steps:\n",
    "\n",
    "1. Calculate prior mean, $\\mu_{prior}$\n",
    "\\begin{equation}\n",
    "\\mu_{prior} = \\beta X + b\n",
    "\\end{equation}\n",
    "\n",
    "Initialize the first estimated prior mean and store in the cache. \n",
    "Future calculations will use the function calc_prior_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prior_mean(X,parameters):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- input data on characteristics of defendant (size # obs, # features)\n",
    "    parameters -- python dictionary containing initialized parameters\n",
    "    \n",
    "    Returns:\n",
    "    cache['mu'] -- mean of judge's prior belief on defendant\n",
    "    \"\"\"\n",
    "    \n",
    "    B = parameters['B']\n",
    "    b = parameters['b']\n",
    "    \n",
    "    # Calculate judge's prior odds  from defendant features\n",
    "    mu_prior = np.dot(B.T,X.T)+b\n",
    "\n",
    "    return mu_prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Estimate the standard deviation of the risk assessment score (i.e. perceived confidence in the anchor info):**\n",
    "\n",
    "**We're not currently including this in further calculations**\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma_{ra}^2 = var_{ra} = \\left \\{\n",
    "\t\\begin{array}{ll}\n",
    "        q \\cdot var_{prior} & if |\\mu_{ra} - \\mu_{prior}|<\\Theta \\\\\n",
    "        \\infty & otherwise\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_var_ra(var_prior,mu_prior,mu_ra,q,theta): \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "\n",
    "    var_ra = [q*var_prior if np.abs(mu_ra[i]-mu_prior[i])>theta else float(\"inf\") for i in range(len(mu_prior))]\n",
    "    \n",
    "    #cache['var_ra'] = np.array(var_ra)\n",
    "    \n",
    "    return var_ra \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Calculate the posterior distribution of a judge's beliefs on defendant, $\\phi_{post}(\\mu_{post},\\sigma_{post}^2)$, and probability of making decision, $\\hat{y}$:**\n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\phi_{prior}(\\mu_{prior},\\sigma_{prior}^2) = \\mathcal{N}(\\mu_{prior},\\sigma_{prior}^2)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "    \\phi_{ra}(\\mu_{ra},\\sigma_{ra}^2) = \\mathcal{N}(\\mu_{ra},\\sigma_{ra}^2)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\phi_{post}(\\mu_{post},\\sigma_{post}^2) =  \\mathcal{N}(\\mu_{post},\\sigma_{post}^2)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    = \\frac{\\phi_{prior}(\\mu_{prior},\\sigma_{prior}^2)\\phi_{ra}(\\mu_{ra},\\sigma_{ra}^2)}{\\int \\phi_{prior}(\\mu_{prior},\\sigma_{prior}^2)\\phi_{ra}(\\mu_{ra},\\sigma_{ra}^2)}\n",
    "\\end{equation}\n",
    "\n",
    "where:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mu_{post} = \\left \\{\n",
    "\t\\begin{array}{ll}\n",
    "        \\mu_{prior} \\cdot \\frac{q}{q+1} + \\mu_{ra} \\cdot \\frac{1}{q+1} & if |\\mu_{ra} - \\mu_{prior}|<\\Theta \\\\\n",
    "        \\mu_{prior} & otherwise\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma_{post}^2 = var_{post} = \\left \\{\n",
    "\t\\begin{array}{ll}\n",
    "        var_{prior} \\cdot \\frac{q}{q+1} & if |\\mu_{ra} - \\mu_{prior}|<\\Theta \\\\\n",
    "        var_{prior} & otherwise\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_post_mean(mu_prior, mu_ra, q, theta):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "\n",
    "    Returns:\n",
    "    mean -- posterior belief distibution mean\n",
    "    \"\"\"\n",
    "\n",
    "    mu_post = [(mu_prior[i]*(q/(q+1)))+(mu_ra[i]/(q+1)) if np.abs(mu_ra[i]-mu_prior[i])>theta else mu_prior[i] for i in range(len(mu_prior))]\n",
    "\n",
    "    return mu_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_post_var(mu_prior, mu_ra, var_prior, q, theta):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    sigma -- prior standard deviation\n",
    "    lmbda -- standard deviation of perceived risk assessment\n",
    "    \n",
    "    Returns:\n",
    "    sd -- posterior belief distribution standard deviation\n",
    "    \"\"\"\n",
    "    \n",
    "    var_post = [var_prior*(q/(q+1)) if np.abs(mu_ra[i]-mu_prior[i])>theta else var_prior for i in range(len(mu_prior))]\n",
    "\n",
    "    return var_post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Calculate the probability of detaining defendant as area under the posterior belief curve $\\geq$ decision threshold, $\\tau$**\n",
    "\n",
    "\\begin{equation}\n",
    "\\Phi(\\tau;\\mu_{post},\\sigma_{post}) = \\int_\\tau^{\\infty} \\phi_{post}(\\tau; \\mu_{post},\\sigma_{post}^2)\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_Phi(mu_post,var_post,tau):    \n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    mu -- prior mean\n",
    "    sigma -- prior standard deviation\n",
    "    risk_assessment -- algorithmic risk assessment prediction\n",
    "    lmbda -- standard deviation of perceived risk assessment\n",
    "    tau -- some threshold above which judge's will detain a defendant\n",
    "    \n",
    "    Returns:\n",
    "    y -- probability of drawing from the region [tau,10]\n",
    "    \"\"\"\n",
    "\n",
    "    Phi = []\n",
    "    for i in range(len(mu_post)):\n",
    "        posterior = scipy.stats.norm(loc=mu_post[i],scale=np.sqrt(var_post[i]))\n",
    "        Phi.append(1 - posterior.cdf(tau))\n",
    "    \n",
    "    # some pred_y = 0 or 1 due to rounding in pythong, which produces an error when take log; add a tiny little number to get around this.\n",
    "    Phi = [1e-16 if i==0 else i for i in Phi]\n",
    "    Phi = np.array([1-1e-16 if i==1 else i for i in Phi])\n",
    "\n",
    "    return Phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) Compute negative log likelihood**\n",
    "\n",
    "We are going to penalize $\\mu_{prior}$ if it goes less than 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "g(1-\\mu_{prior}) = \\left \\{\n",
    "\t\\begin{array}{ll}\n",
    "        0 & if 1 - \\mu_{prior}<0 \\\\\n",
    "        k(1-\\mu_{prior})^3 & if 1-\\mu_{prior}\\geq0\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "h(10-\\mu_{prior}) = \\left \\{\n",
    "\t\\begin{array}{ll}\n",
    "        0 & if \\mu_{prior}-10 < 0 \\\\\n",
    "        k(\\mu_{prior}-10)^3 & if \\mu_{prior}-10\\geq0\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{L}(\\Phi(\\tau;\\mu_{post},\\sigma_{post}^2), y_i) = y_i \\log (1-\\Phi(\\tau;\\mu_{post},\\sigma_{post}^2)) + (1-y_i) \\log \\Phi(\\tau;\\mu_{post},\\sigma_{post}^2) + g(1-\\mu_{prior}) + h(\\mu_{prior}-10)\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_L(Phi,y,mu_prior,k):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    pred_y -- predicted probability of drawing a belief from the posterior distribution > tau\n",
    "    true_y -- known decision by judge on defendant \n",
    "    \n",
    "    Returns:\n",
    "    L(y_pred,y_true) -- negative log likelihood\n",
    "    \"\"\"\n",
    "    y = np.array(y)\n",
    "    L=[]\n",
    "    \n",
    "    # penalize both 1-mu_prior >= 0 & mu_prior-10 >= 0\n",
    "    for i in range(len(mu_prior)):\n",
    "        if 1 - mu_prior[i]<0: # this is for when mu_prior < 1\n",
    "            g = 0\n",
    "        else:\n",
    "            g = k*((1-mu_prior[i])**3)\n",
    "\n",
    "        if mu_prior[i] - 10 < 0: # this is for when mu_prior > 10\n",
    "            h = 0\n",
    "        else:\n",
    "            h = k*((mu_prior[i]-10)**3)\n",
    "            \n",
    "        nLL = -(y[i]*np.log(1-Phi[i])+(1-y[i])*np.log(Phi[i]))\n",
    "        \n",
    "        L.append(nLL+g+h)\n",
    "    \n",
    "    # penalize 1-mu_prior >= 0\n",
    "    #L = [-(y[i]*np.log(1-Phi[i])+(1-y[i])*np.log(Phi[i])) if 1-mu_prior[i]<0 else -(y[i]*np.log(1-Phi[i])+(1-y[i])*np.log(Phi[i]))+(k*((1-mu_prior[i])**3)) for i in range(len(mu_prior))]\n",
    "    \n",
    "    # no penalties\n",
    "    #L = -((np.array(y)*np.log(1-np.array(Phi)))+(1-np.array(y))*np.log(np.array(Phi)))\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Calculate derivatives for gradient descent**\n",
    "\n",
    "Given $\\mathcal{L}(\\Phi(\\tau;\\mu_{post},var_{post}^2),y_i)$ calculate the gradients $\\frac{d\\mathcal{L}}{d\\beta}$, $\\frac{d\\mathcal{L}}{db}$, $\\frac{d\\mathcal{L}}{dvar_{prior}}$, $\\frac{d\\mathcal{L}}{dq}$,$\\frac{d\\mathcal{L}}{d\\tau}$ using the following:\n",
    "\n",
    "\\begin{equation}\n",
    "    d\\mathcal{L} = \\phi_{post}\\left((1-y)\\cdot\\frac{\\phi_{post}}{\\Phi} - y\\cdot\\frac{\\phi_{post}}{1-\\Phi} \\right)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\phi_{post}}{d\\mu_{post}} = \\frac{\\tau-\\mu_{post}}{var_{post}^{3/2}\\sqrt{2\\pi}}\\cdot exp \\left( \\frac{(\\tau-\\mu_{post})^2}{2\\cdot var_{post}} \\right)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\phi_{post}}{dvar_{post}} = \\left(\\frac{(\\tau-\\mu_{post})^2}{2 \\cdot var_{post}^{5/2} \\cdot \\sqrt{2\\pi}} - \\frac{1}{2 \\cdot var_{post}^{3/2} \\cdot \\sqrt{2\\pi}} \\right) \\cdot exp \\left[- \\frac{(\\tau-\\mu_{post})^2}{2\\cdot var_{post}} \\right]\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\phi_{post}}{d\\tau}= -\\frac{\\tau-\\mu_{post}}{var_{post}^{3/2} \\sqrt{2\\pi}}exp\\left[-\\frac{(\\tau-\\mu_{post})^2}{2var_{post}} \\right]\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\mu_{post}}{d\\mu_{prior}} = \n",
    "    \\left \\{\n",
    "\t\\begin{array}{ll}\n",
    "        \\frac{q}{q+1} & if |\\mu_{ra} - \\mu_{prior}|<\\Theta \\\\\n",
    "        1 & otherwise\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\mu_{post}}{dq} = \n",
    "        \\left \\{\n",
    "\t\\begin{array}{ll}\n",
    "        \\frac{\\mu_{prior}}{1+q} - \\frac{\\mu_{ra}}{(1+q)^2}-\\frac{q\\cdot\\mu_{prior}}{(1+q)^2} & if |\\mu_{ra} - \\mu_{prior}|<\\Theta \\\\\n",
    "        0 & otherwise\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "\\end{equation}        \n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{dvar_{post}}{dq} = \n",
    "    \\left \\{\n",
    "\t\\begin{array}{ll}\n",
    "        \\frac{var_{prior}}{q+1} - \\frac{q \\cdot var_{prior}}{(q+1)^2} & if |\\mu_{ra} - \\mu_{prior}|<\\Theta \\\\\n",
    "        0 & otherwise\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{dvar_{post}}{dvar_{prior}} = \n",
    "        \\left \\{\n",
    "\t\\begin{array}{ll}\n",
    "        \\frac{q}{q+1} & if |\\mu_{ra} - \\mu_{prior}|<\\Theta \\\\\n",
    "        1 & otherwise\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    if 1-\\mu_{prior} \\geq 0: \\frac{d\\mathcal{L}}{d\\mu_{prior}} = -3k(1-\\mu_{prior})^2\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    if \\mu_{prior}-10 \\geq 0: \\frac{d\\mathcal{L}}{d\\mu_{prior}} = 3k(\\mu_{prior}-10)^2\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    else: \\frac{d\\mathcal{L}}{d\\mu_{prior}} = 0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_component_derivs(X, y, parameters, derivatives, theta, mu_prior,mu_ra,mu_post,var_post,Phi,k): \n",
    "    \n",
    "    # retrieve variables\n",
    "    mu_ra = np.array(mu_ra)\n",
    "    B = parameters['B']\n",
    "    b = parameters['b']\n",
    "    q = parameters['q']\n",
    "    var_prior = parameters['var_prior']\n",
    "    tau = parameters['tau']\n",
    "\n",
    "    # Calculate Derivatives / Partial Derivatives\n",
    "\n",
    "# dL\n",
    "    post_normal = scipy.stats.norm(mu_post,np.sqrt(var_post))\n",
    "    phi_post = post_normal.pdf(tau)\n",
    "    #phi_post = (1/(np.sqrt(2*math.pi*var_post)))*np.exp(-(((tau-mu_post)**2)/(2*var_post)))\n",
    "    \n",
    "    derivatives['dL'] = phi_post*((np.array(1-y)*(phi_post/Phi))-(np.array(y)*(phi_post/(1-Phi))))\n",
    "\n",
    "# dphi_post / dmu_post\n",
    "    var_post_exp = [vp**(3/2) for vp in var_post]\n",
    "    p1 = np.subtract(tau,mu_post)/np.multiply(var_post_exp,((2*math.pi)**(1/2)))\n",
    "    p2 = -(np.subtract(tau,mu_post)**2 / np.multiply(2,var_post))\n",
    "    derivatives['dphipost_dmupost'] = p1*np.exp(p2.astype(float))\n",
    "    \n",
    "# dphi_post / dvar_post\n",
    "    var_post_exp_1 = [vp**(5/2) for vp in var_post]\n",
    "    p1 = (np.subtract(tau,mu_post)**2)/np.multiply(np.multiply(2,var_post_exp_1),((2*math.pi)**(1/2)))\n",
    "    var_post_exp_2 = [vp**(3/2) for vp in var_post]\n",
    "    p2 = 1/(np.multiply(2,var_post_exp_2)*((2*math.pi)**(1/2)))\n",
    "    p3 = (-((np.subtract(tau,mu_post)**2)/np.multiply(2,var_post)))\n",
    "    derivatives['dphipost_dvarpost'] = (p1-p2)*np.exp(p3.astype(float))\n",
    "    \n",
    "#dphi_post / dtau\n",
    "    var_post_exp = [vp**(3/2) for vp in var_post]\n",
    "    p1 = -(np.subtract(tau,mu_post)/(var_post_exp)*((2*math.pi)**(1/2)))\n",
    "    p2 = -((np.subtract(tau,mu_post)**2)/np.multiply(2,var_post))\n",
    "    derivatives['dphipost_dtau'] = p1*np.exp(p2)\n",
    "           \n",
    "# dL_dmuprior\n",
    "    derivatives['dL_dmuprior']=[]\n",
    "    for i in range(len(mu_prior)):\n",
    "        if 1-mu_prior[i]>=0:\n",
    "            derivatives['dL_dmuprior'].append(-3*k*((1-mu_prior[i])**2))\n",
    "        elif mu_prior[i]-10>=0:\n",
    "            derivatives['dL_dmuprior'].append(3*k*((mu_prior[i]-10)**2))\n",
    "        else:\n",
    "            derivatives['dL_dmuprior'].append(0)\n",
    "    derivatives['dL_dmuprior']=np.array(derivatives['dL_dmuprior'])\n",
    "        \n",
    "# dmu_prior / dB\n",
    "    #derivatives['dmuprior_dB'] = X\n",
    "\n",
    "# dmu_prior / db\n",
    "    #derivatives['dmuprior_db'] = 1\n",
    "    \n",
    "    dmupost_dmuprior = []\n",
    "    dvarpost_dq = []\n",
    "    dmupost_dq = []\n",
    "    dvarpost_dvarprior = []\n",
    "    \n",
    "    for i in range(len(mu_prior)):\n",
    "        if np.abs(mu_prior[i] - mu_ra[i]) < theta:\n",
    "\n",
    "            # dmu_post/dmu_prior\n",
    "            dmupost_dmuprior.append((q/(q+1))[0])\n",
    "\n",
    "            #dvarpost_dq\n",
    "            dvarpost_dq.append(((var_prior/(q+1))-((q*var_prior)/((q+1)**2)))[0])\n",
    "\n",
    "            #dmupost_dq\n",
    "            dmupost_dq.append(((mu_prior[i]/(q+1)) - (mu_ra[i]/((q+1)**2)) - ((mu_prior[i]*q)/((q+1)**2)))[0])\n",
    "\n",
    "            #dvarpost_dvarprior\n",
    "            dvarpost_dvarprior.append(0)\n",
    "\n",
    "        else:\n",
    "\n",
    "            # dmu_post/dmu_prior\n",
    "            dmupost_dmuprior.append(1)\n",
    "\n",
    "            #dvarpost_dq\n",
    "            dvarpost_dq.append(0)\n",
    "\n",
    "            #dmupost_dq\n",
    "            dmupost_dq.append(0)\n",
    "\n",
    "            #dvarpost_dvarprior\n",
    "            dvarpost_dvarprior.append(1)\n",
    "        \n",
    "        derivatives['dmupost_dmuprior'] = np.array(dmupost_dmuprior)\n",
    "        derivatives['dvarpost_dq'] = np.array(dvarpost_dq)\n",
    "        derivatives['dmupost_dq'] = np.array(dmupost_dq)\n",
    "        derivatives['dvarpost_dvarprior'] = np.array(dvarpost_dvarprior)\n",
    "    \n",
    "    return derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Use chain rule to calculate gradients**\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\mathcal{L}}{d\\beta} = d\\mathcal{L}\\cdot\\frac{\\partial\\phi_{post}}{\\partial\\mu_{post}}\\cdot \\frac{\\partial\\mu_{post}}{\\partial\\mu_{prior}}\\cdot \\frac{d\\mu_{prior}}{d\\beta} + \\frac{d\\mathcal{L}}{d\\mu_{prior}}\\cdot \\frac{d\\mu_{prior}}{d\\beta}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\mathcal{L}}{db} = d\\mathcal{L}\\cdot\\frac{\\partial\\phi_{post}}{\\partial\\mu_{post}}\\cdot \\frac{\\partial\\mu_{post}}{\\partial\\mu_{prior}}\\cdot \\frac{d\\mu_{prior}}{db} + \\frac{d\\mathcal{L}}{d\\mu_{prior}}\\cdot \\frac{d\\mu_{prior}}{db}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\phi_{post}}{dvar_{prior}} = \\frac{d\\phi_{post}}{dvar_{post}} \\cdot \\frac{dvar_{post}}{dvar_{prior}} \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\phi_{post}}{dq} = \\frac{d\\phi_{post}}{dvar_{post}} \\cdot \\frac{dvar_{post}}{dq} + \\frac{d\\phi_{post}}{d\\mu_{post}} \\cdot \\frac{d\\mu_{post}}{dq} \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\phi_{post}}{d\\tau}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradients(grads, derivatives, mu_prior, X): \n",
    "# Retrieve variables\n",
    "    dL = derivatives['dL']\n",
    "    dL_dmuprior = derivatives['dL_dmuprior']\n",
    "    dphipost_dmupost = derivatives['dphipost_dmupost']\n",
    "    dphipost_dvarpost = derivatives['dphipost_dvarpost']\n",
    "    dphipost_dtau = derivatives['dphipost_dtau']\n",
    "    dmupost_dmuprior = derivatives['dmupost_dmuprior']\n",
    "    dvarpost_dq = derivatives['dvarpost_dq']\n",
    "    dmupost_dq = derivatives['dmupost_dq']\n",
    "    dvarpost_dvarprior = derivatives['dvarpost_dvarprior']\n",
    "\n",
    "# dL_dB\n",
    "    dldB =[dL[i]*dphipost_dmupost[i]*dmupost_dmuprior[i]+dL_dmuprior[i] for i in range(len(mu_prior))]\n",
    "    dL_dB = np.dot(dldB,X)\n",
    "    grads['dB'] = dL_dB\n",
    "\n",
    "# dL_db\n",
    "    dldb =[dL[i]*dphipost_dmupost[i]*dmupost_dmuprior[i]+dL_dmuprior[i] for i in range(len(mu_prior))]\n",
    "    dL_db = np.sum(dldb)\n",
    "    grads['db'] = dL_db\n",
    "\n",
    "#dL_dvarprior\n",
    "    dL_dvarprior = np.sum(dL*dphipost_dvarpost*dvarpost_dvarprior)         \n",
    "    grads['dvar_dprior'] = dL_dvarprior\n",
    "\n",
    "# dL_dq\n",
    "    dL_dq = np.sum(dL*((dphipost_dvarpost*dvarpost_dq)+(dphipost_dmupost*dmupost_dq)))\n",
    "    grads['dq'] = dL_dq\n",
    "\n",
    "# dL_dtau\n",
    "    dL_dtau = np.sum(dL*dphipost_dtau)\n",
    "    grads['dtau'] = dL_dtau    \n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8) Update parameters with gradients**\n",
    "\n",
    "\\begin{equation}\n",
    "\\beta' = \\beta - \\alpha \\frac{d\\mathcal{L}}{d\\beta} \\\\\n",
    "b' = b - \\alpha \\frac{d\\mathcal{L}}{db} \\\\\n",
    "q' = q - \\alpha \\frac{d\\mathcal{L}}{dq} \\\\\n",
    "var_{prior}' = var_{prior}-\\alpha\\frac{d\\mathcal{L}}{dvar_{prior}} \\\\\n",
    "\\tau' = \\tau - \\alpha \\frac{dL}{d\\tau}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    parameters -- dictionary containing parameters \n",
    "    grads -- dictionary containing gradients \n",
    "    learning rate\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- dictionary containing updated parameters \n",
    "    \"\"\"\n",
    "    B = parameters['B']\n",
    "    b = parameters['b']\n",
    "    q = parameters['q']\n",
    "    var_prior = parameters['var_prior']\n",
    "    tau = parameters['tau']\n",
    "    \n",
    "    dB = np.array([i for i in grads['dB']])\n",
    "    db = grads['db']\n",
    "    dq = grads['dq']\n",
    "    dvar_dprior = grads['dvar_dprior']\n",
    "    dtau = grads['dtau']\n",
    "    \n",
    "    parameters['B'] = np.array([B[i]-(dB[i]*learning_rate) for i in range(B.shape[0])])\n",
    "    parameters['b'] = b-(learning_rate*db)\n",
    "    parameters['q'] = q-(learning_rate*dq)\n",
    "    parameters['var_prior'] = var_prior-(learning_rate*dvar_dprior)\n",
    "    parameters['tau'] = tau-(learning_rate*dtau)\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

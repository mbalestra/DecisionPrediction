{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "from operator import add\n",
    "\n",
    "from ipynb.fs.full.GenerateData import generatedata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0) Define variables**\n",
    "\n",
    "$ \\{x_{1}, x_{2},...x_{k}\\} \\in X$, Observed features of defendant\n",
    " \n",
    "$\\mu_{prior}$, Judge's mean prior belief about a defendant; $\\textit{most probable}$ risk prediction\n",
    "\n",
    "$\\sigma_{prior}$, Standard deviation of judge's prior belief on a defendant; corresponds to a judge's $\\textit{uncertainty}$ about prediction\n",
    "\n",
    "$\\mu_{ra}$, Observed algorithmic risk assessment prediction; mean of normally-distributed perceived anchor information\n",
    "\n",
    "$\\sigma_{ra}$, Perceived anchor $\\textit{influence}$; Corresponds to S.D. of risk assessment (when perceived as containing a lot of information S.D. will be lower and vice versa).\n",
    "\n",
    "$q$, Parameter mapping $\\mu_{prior},\\sigma_{prior}$ onto $\\mu_{post},\\sigma_{post}$\n",
    "\n",
    "$\\Theta$, Threshold distance between $\\mu_{prior}$ and $\\mu_{ra}$ after which $\\mu_{ra}$ has no (or minimal) effect on $\\mu_{prior}$\n",
    "\n",
    "$\\mu_{post}$, Judge's mean posterior belief\n",
    "\n",
    "$\\sigma_{post}$, Standard deviation of judge's posterior belief \n",
    "\n",
    "$\\tau$, Decision making threshold\n",
    "\n",
    "$\\phi_{prior}(\\tau;\\mu_{prior},\\sigma_{prior})$, Gaussian distribution representing judge's prior belief\n",
    "\n",
    "$\\phi_{post}(\\tau;\\mu_{post},\\sigma_{post})$, Gaussian distribution representing the judge's posterior belief\n",
    "\n",
    "$\\Phi_{post}(\\tau;\\mu_{post},\\sigma_{post})$, Probability of drawing a belief from the posterior greater than threshold $\\tau$\n",
    "\n",
    "$y$, Judge's observed decision on defendant\n",
    " \n",
    "$\\alpha$, Learning rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Helper functions**\n",
    "\n",
    "**(a) Initialize parameters**\n",
    "\n",
    "$\\beta_{1}$ (nx1), $\\beta_{2}$ (nx1), and $w$ (1x1) are randomly initialized (>0);\n",
    "$b$ (1x1) and $c$ (1x1) are initialized as zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(X,lower,upper):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    \n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    random.seed(22)#2304\n",
    "    \n",
    "    # of parameters\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    B = [random.random() for i in range(n)]\n",
    "    b = random.random()*10\n",
    "    q = random.random()\n",
    "    sd = random.random()*10\n",
    "    tau = random.randint(lower, upper)\n",
    "    Theta = random.randint(lower, upper)\n",
    "    scale = 25\n",
    "    \n",
    "    parameters = {\"B\": np.array([B]).T,\n",
    "                  \"b\": b,\n",
    "                  \"q\" : q,\n",
    "                  \"sd_prior\" : sd,\n",
    "                  \"tau\" : tau,\n",
    "                  \"Theta\" : Theta,\n",
    "                  \"scale\": scale}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary to store derivatives\n",
    "def initialize_dicts():\n",
    "    derivatives = {\n",
    "        \"dL_dphi\": [],\n",
    "        \"dphipost_dmupost\": [],\n",
    "        \"dphipost_dsdpost\": [],\n",
    "        \"dphipost_dtau\": [],\n",
    "        \"dmupost_dmuprior\": [],\n",
    "        \"dsdpost_dq\": [],\n",
    "        \"dmupost_dq\": [],\n",
    "        \"dsdpost_dsdprior\": [],\n",
    "        \"dmupost_dI\" : [],\n",
    "        \"dsdpost_dI\" : [],\n",
    "        \"dI_dd\" : [],\n",
    "        \"dd_dmuprior\" : [],\n",
    "        \"dd_dtheta\" : []\n",
    "    }\n",
    "\n",
    "    grads = {\n",
    "        \"dB\" : [],\n",
    "        \"db\" : [],\n",
    "        \"dsdprior\" : [],\n",
    "        \"dq\" : [],\n",
    "        \"dtau\" : [],\n",
    "        \"dTheta\" : []\n",
    "    }\n",
    "    \n",
    "    return derivatives,grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Forward**\n",
    "\n",
    "**(a) Estimate mean of prior belief distribution**\n",
    "\n",
    "Given {$\\beta, b, \\sigma, \\theta, \\tau, w$}, want to calculate loss, $\\mathcal{L}(\\hat{y},y_i)$ using the following steps:\n",
    "\n",
    "1. Calculate prior mean, $\\mu_{prior}$\n",
    "\\begin{equation}\n",
    "\\mu_{prior} = \\beta X + b\n",
    "\\end{equation}\n",
    "\n",
    "Initialize the first estimated prior mean and store in the cache. \n",
    "Future calculations will use the function calc_prior_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prior_mean(X,parameters):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    \n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    \n",
    "    B = parameters['B']\n",
    "    b = parameters['b']\n",
    "    \n",
    "    mu_prior = np.dot(B.T,X.T)+b\n",
    "    \n",
    "    return mu_prior[0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Estimate the standard deviation of the risk assessment score (i.e. perceived confidence in the anchor info):**\n",
    "\n",
    "**We're not currently including this in further calculations**\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma_{ra}^2 = var_{ra} = \\left \\{\n",
    "\t\\begin{array}{ll}\n",
    "        q \\cdot var_{prior} & if |\\mu_{ra} - \\mu_{prior}|<\\Theta \\\\\n",
    "        \\infty & otherwise\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def calc_var_ra(sd_prior,mu_prior,mu_ra,q,theta): \n",
    "#    \"\"\"\n",
    "#    #Arguments:\n",
    "\n",
    "#    #Returns:\n",
    "#    \"\"\"\n",
    "\n",
    "#    var_ra = [q*sd_prior if np.abs(mu_ra[i]-mu_prior[i])<theta else float(\"inf\") for i in range(len(mu_prior))]\n",
    "\n",
    "#    return var_ra "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Calculate the posterior distribution of a judge's beliefs on defendant, $\\phi_{post}(\\mu_{post},\\sigma_{post}^2)$, and probability of making decision, $\\hat{y}$:**\n",
    "\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\phi_{prior}(\\mu_{prior},\\sigma_{prior}^2) = \\mathcal{N}(\\mu_{prior},\\sigma_{prior}^2)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "    \\phi_{ra}(\\mu_{ra},\\sigma_{ra}^2) = \\mathcal{N}(\\mu_{ra},\\sigma_{ra}^2)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\phi_{post}(\\mu_{post},\\sigma_{post}^2) =  \\mathcal{N}(\\mu_{post},\\sigma_{post}^2)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    = \\frac{\\phi_{prior}(\\mu_{prior},\\sigma_{prior}^2)\\phi_{ra}(\\mu_{ra},\\sigma_{ra}^2)}{\\int \\phi_{prior}(\\mu_{prior},\\sigma_{prior}^2)\\phi_{ra}(\\mu_{ra},\\sigma_{ra}^2)}\n",
    "\\end{equation}\n",
    "\n",
    "where:\n",
    "\n",
    "\\begin{equation}\n",
    "d = |\\mu_{ra}-\\mu_{prior}|-\\Theta\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "I = 1 - \\frac{1}{1+e^{-d*scale}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\mu_{post} = I\\cdot\\left(\\mu_{prior} \\cdot \\frac{q}{q+1} + \\mu_{ra} \\cdot \\frac{1}{q+1}\\right) + (1-I)\\cdot\\mu_{prior}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma_{post} = I\\cdot\\left(\\sigma_{prior} \\cdot \\sqrt{\\frac{q}{q+1}}\\right) + (1-I)\\cdot\\sigma_{prior}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = list(range(-10,10))\n",
    "#test_sig = [1-(1/(1+np.exp(-25*t))) for t in test]\n",
    "#plt.plot(test,test_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_post_mean(mu_prior, mu_ra, parameters):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    theta = parameters['Theta']\n",
    "    q = parameters['q']\n",
    "    scale = parameters['scale']\n",
    "    \n",
    "    difference = [np.abs(mu_ra[i]-mu_prior[i])-theta for i in range(len(mu_prior))]\n",
    "    I = [1-(1/(1+np.exp(-scale*d))) for d in difference]\n",
    "    mu_post = [(I[i]*((mu_prior[i]*(q/(q+1)))+(mu_ra[i]/(q+1))))+((1-I[i])*mu_prior[i]) for i in range(len(mu_prior))]\n",
    "    \n",
    "    return mu_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_post_sd(mu_prior, mu_ra, parameters):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    \n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    q = parameters['q']\n",
    "    sd_prior = parameters['sd_prior']\n",
    "    theta = parameters['Theta']\n",
    "    scale = parameters['scale']\n",
    "    \n",
    "    difference = [np.abs(mu_ra[i]-mu_prior[i])-theta for i in range(len(mu_prior))]\n",
    "    I = [1-(1/(1+np.exp(-scale*d))) for d in difference]\n",
    "    sd_post = [(I[i]*(sd_prior*np.sqrt(q/(q+1))))+((1-I[i])*sd_prior) for i in range(len(mu_prior))]\n",
    "    \n",
    "    return sd_post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Calculate the probability of detaining defendant as area under the posterior belief curve $\\geq$ decision threshold, $\\tau$**\n",
    "\n",
    "\\begin{equation}\n",
    "\\phi(\\tau; \\mu_{post},\\sigma_{post}) = \\mathcal{N}(\\tau;\\mu_{post},\\sigma_{post}) \\\\\n",
    "\\Phi(\\tau;\\mu_{post},\\sigma_{post}) = \\int_\\tau^{\\infty} \\phi_{post}(\\tau; \\mu_{post},\\sigma_{post}) \\\\\n",
    "\\hat{y}=1-\\Phi(\\tau;\\mu_{post},\\sigma_{post}) \n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_y(mu_post,sd_post,parameters):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    \n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    tau = parameters['tau']\n",
    "\n",
    "    y_pred = [1 - norm.cdf(tau,loc=mu_post[i],scale=sd_post[i]) for i in range(len(mu_post))]\n",
    "    \n",
    "    y_pred = [1e-13 if p==0 else p for p in y_pred]\n",
    "    y_pred = [1-1e-13 if p==1 else p for p in y_pred]\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e) Compute negative log likelihood**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\mathcal{L}(\\hat{y}, y_i) = \\frac{1}{m}\\sum_{1=1}^{m}- y_i \\log (\\hat{y}) - (1-y_i) \\log (1-\\hat{y})\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_L(y_pred,Y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        loss += -(Y[i]*np.log(y_pred[i]))-((1-Y[i])*np.log(1-y_pred[i]))\n",
    "\n",
    "    L = loss/len(y_pred)\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Calculate derivatives for gradient descent**\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\mathcal{L}}{d\\phi_{post}} = -1 \\cdot \\phi_{post} \\cdot \\left(-\\frac{y}{\\hat{y}}+\\frac{1-y}{1-\\hat{y}}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\phi_{post}}{d\\mu_{post}} = \\frac{\\tau-\\mu_{post}}{\\sigma_{post}^3\\cdot\\sqrt{2\\pi}}\\cdot exp \\left(- \\frac{(\\tau-\\mu_{post})^2}{2\\cdot \\sigma_{post}^2} \\right)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\phi_{post}}{d\\sigma_{post}} = \\left(\\frac{(\\tau-\\mu_{post})^2}{\\sigma_{post}^4\\sqrt{2\\pi}} - \\frac{1}{\\sigma_{post}^2 \\sqrt{2\\pi}} \\right) \\cdot exp \\left[- \\frac{(\\tau-\\mu_{post})^2}{2\\cdot \\sigma_{post}^2} \\right]\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\phi_{post}}{d\\tau}= -\\frac{\\tau-\\mu_{post}}{\\sigma_{post}^3 \\sqrt{2\\pi}}exp\\left[-\\frac{(\\tau-\\mu_{post})^2}{2\\sigma_{post}^3} \\right]\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\mu_{post}}{d\\mu_{prior}} = \n",
    "    1-I+\\frac{I\\cdot q}{q+1}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\mu_{post}}{dq} = I\\cdot\\left(\\frac{\\mu_{prior}}{1+q} - \\frac{\\mu_{ra}}{(1+q)^2}-\\frac{q\\cdot\\mu_{prior}}{(1+q)^2}\\right)\n",
    "\\end{equation}        \n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\sigma_{post}}{dq} = I\\cdot \\sigma_{prior} \\left( \\frac{-\\frac{q}{(1+q)^2} + \\frac{1}{1+q}}{2\\sqrt{\\frac{q}{q+1}}} \\right)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\sigma_{post}}{d\\sigma_{prior}} = 1-I+I\\cdot\\sqrt{\\frac{q}{q+1}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{d\\mu_{prior}}{d\\beta} = X\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{d\\mu_{prior}}{db} = 1\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\mu_{post}}{dI} = -\\mu_{prior}+\\frac{\\mu_{ra}}{q+1}+\\frac{\\mu_{prior}\\cdot q}{q+1}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\sigma_{post}}{dI} = -\\sigma_{prior}+\\sigma_{prior}\\cdot\\sqrt{\\frac{q}{q+1}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{dI}{dd} = - \\frac{scale \\cdot e^{-d \\cdot scale}}{(1+e^{-d \\cdot scale})^2} \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{dd}{d\\mu_{prior}} =\n",
    "    \\left \\{\n",
    "\t\\begin{array}{ll}\n",
    "        -1 & if \\mu_{ra} - \\mu_{prior}>0 \\\\\n",
    "        1 & if \\mu_{ra} - \\mu_{prior}<0\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{dd}{d\\Theta} = -1\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_component_derivs(X, parameters, derivatives, mu_prior, mu_ra, mu_post, sd_post, y_pred, Y):\n",
    "        \n",
    "    B = parameters['B']\n",
    "    b = parameters['b']\n",
    "    q = parameters['q']\n",
    "    sd_prior = parameters['sd_prior']\n",
    "    tau = parameters['tau']\n",
    "    Theta = parameters['Theta']\n",
    "    scale = parameters['scale']\n",
    "    \n",
    "    difference = [np.abs(mu_ra[i]-mu_prior[i])-Theta for i in range(len(mu_prior))]\n",
    "    Indicator = [1-(1/(1+np.exp(-1*d*scale))) for d in difference]\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        \n",
    "        #retrieve variables\n",
    "        s_post = sd_post[i]\n",
    "        y = Y[i]\n",
    "        m_prior = mu_prior[i]\n",
    "        m_post = mu_post[i]\n",
    "        m_ra = mu_ra[i]\n",
    "        y_p = y_pred[i]\n",
    "        d_0 = difference[i]\n",
    "        I = Indicator[i]\n",
    "        \n",
    "        # calculate derivatives / partial derivatives\n",
    "    \n",
    "        # a few expressions for reuse\n",
    "        exponent = np.exp(-((tau-m_post)**2)/(2*(s_post**2)))\n",
    "\n",
    "        # dL/dphi\n",
    "        phi_post = (1/(s_post*np.sqrt(2*math.pi)))*exponent\n",
    "        dL_dphi = -1*phi_post*(((1-y)/(1-y_p))-(-y/y_p))\n",
    "\n",
    "        # dphipost_dmupost\n",
    "        dphipost_dmupost = ((tau-m_post)/((s_post**3)*np.sqrt(2*math.pi)))*exponent \n",
    "\n",
    "        # dphipost_dsdpost\n",
    "        dphi_dsd_1 = ((tau-m_post)**2)/((s_post**4)*np.sqrt(2*math.pi))\n",
    "        dphi_dsd_2 = 1/((s_post**2)*np.sqrt(2*math.pi))\n",
    "        dphipost_dsdpost = (dphi_dsd_1-dphi_dsd_2)*exponent\n",
    "\n",
    "        # dphipost_dtau\n",
    "        dphipost_dtau = -((tau-m_post)/((s_post**3)*np.sqrt(2*math.pi)))*exponent\n",
    "\n",
    "        # dmupost_dmuprior\n",
    "        dmupost_dmuprior = 1-I+((I*q)/(q+1))\n",
    "        \n",
    "        # dmupost_dq\n",
    "        dmupost_dq = I*((m_prior/(1+q)) - (m_ra/((q+1)**2)) - ((m_prior*q)/((q+1)**2)))\n",
    "        \n",
    "        # dsdpost_dq\n",
    "        dsdpost_dq_num = -(q/((1+q)**2))+(1/(1+q))\n",
    "        dsdpost_dq_den = 2*np.sqrt(q/(1+q))\n",
    "        dsdpost_dq = I*sd_prior*(dsdpost_dq_num/dsdpost_dq_den)\n",
    "        \n",
    "        # dsdpost_dsdprior\n",
    "        dsdpost_dsdprior = 1-I+(I*np.sqrt(q/(q+1)))\n",
    "        \n",
    "        # dmupost_dI\n",
    "        dmupost_dI = -m_prior + (m_ra/(q+1)) + ((m_prior*q)/(q+1))\n",
    "        \n",
    "        # dsdpost_dI\n",
    "        dsdpost_dI = -sd_prior+(sd_prior*np.sqrt(q/(q+1)))\n",
    "        \n",
    "        # dI_dd\n",
    "        dI_dd = -(scale*np.exp(-1*scale*d_0))/((1+np.exp(-1*scale*d_0))**2)\n",
    "        \n",
    "        # dd_dmuprior\n",
    "        if m_ra-m_prior>0:\n",
    "            dd_dmuprior = -1\n",
    "        else:\n",
    "            dd_dmuprior = 1\n",
    "\n",
    "        # dd_dtheta\n",
    "        dd_dtheta = -1\n",
    "\n",
    "        derivatives['dL_dphi'].append(dL_dphi)\n",
    "        derivatives['dphipost_dmupost'].append(dphipost_dmupost)\n",
    "        derivatives['dphipost_dsdpost'].append(dphipost_dsdpost)\n",
    "        derivatives['dphipost_dtau'].append(dphipost_dtau)\n",
    "        derivatives['dmupost_dmuprior'].append(dmupost_dmuprior)\n",
    "        derivatives['dsdpost_dq'].append(dsdpost_dq)\n",
    "        derivatives['dmupost_dq'].append(dmupost_dq)\n",
    "        derivatives['dsdpost_dsdprior'].append(dsdpost_dsdprior)\n",
    "        derivatives['dmupost_dI'].append(dmupost_dI)\n",
    "        derivatives['dsdpost_dI'].append(dsdpost_dI)\n",
    "        derivatives['dI_dd'].append(dI_dd)\n",
    "        derivatives['dd_dmuprior'].append(dd_dmuprior)\n",
    "        derivatives['dd_dtheta'].append(dd_dtheta)\n",
    "\n",
    "    \n",
    "    return derivatives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Use chain rule to calculate gradients**\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\mathcal{L}}{d\\beta} =  \\frac{1}{m}\\sum_{1=1}^{m}\\frac{d\\mathcal{L}}{d\\phi_{post}}\\cdot \\frac{d\\phi_{post}}{d\\sigma_{post}} \\cdot \\frac{d\\sigma_{post}}{dI} \\cdot \\frac{dI}{dd} \\cdot \\frac{dd}{d\\mu_{prior}} \\cdot \\frac{d\\mu_{prior}}{d\\beta} + \\frac{d\\mathcal{L}}{d\\phi_{post}} \\cdot \\frac{d\\phi_{post}}{d\\mu_{post}} \\cdot \\frac{d\\mu_{post}}{d\\mu_{prior}} \\cdot \\frac{d\\mu_{prior}}{d\\beta} + \\frac{d\\mathcal{L}}{d\\phi_{post}} \\cdot \\frac{d\\phi_{post}}{d\\mu_{post}} \\cdot \\frac{d\\mu_{post}}{dI} \\cdot \\frac{dI}{dd} \\cdot \\frac{dd}{d\\mu_{prior}} \\cdot \\frac{d\\mu_{prior}}{d\\beta}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\mathcal{L}}{db} =  \\frac{1}{m}\\sum_{1=1}^{m}\\frac{d\\mathcal{L}}{d\\phi_{post}}\\cdot \\frac{d\\phi_{post}}{d\\sigma_{post}} \\cdot \\frac{d\\sigma_{post}}{dI} \\cdot \\frac{dI}{dd} \\cdot \\frac{dd}{d\\mu_{prior}} \\cdot \\frac{d\\mu_{prior}}{db} + \\frac{d\\mathcal{L}}{d\\phi_{post}} \\cdot \\frac{d\\phi_{post}}{d\\mu_{post}} \\cdot \\frac{d\\mu_{post}}{d\\mu_{prior}} \\cdot \\frac{d\\mu_{prior}}{db} + \\frac{d\\mathcal{L}}{d\\phi_{post}} \\cdot \\frac{d\\phi_{post}}{d\\mu_{post}} \\cdot \\frac{d\\mu_{post}}{dI} \\cdot \\frac{dI}{dd} \\cdot \\frac{dd}{d\\mu_{prior}} \\cdot \\frac{d\\mu_{prior}}{db}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\mathcal{L}}{d\\sigma_{prior}} = \\frac{1}{m}\\sum_{1=1}^{m}\\frac{d\\mathcal{L}}{d\\phi_{post}}\\cdot\\frac{d\\phi_{post}}{d\\sigma_{post}} \\cdot \\frac{d\\sigma_{post}}{d\\sigma_{prior}} \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\mathcal{L}}{dq} = \\frac{1}{m}\\sum_{1=1}^{m}\\frac{d\\mathcal{L}}{d\\phi_{post}}\\cdot\\frac{d\\phi_{post}}{d\\sigma_{post}} \\cdot \\frac{d\\sigma_{post}}{dq} + \\frac{d\\mathcal{L}}{d\\phi_{post}}\\cdot\\frac{d\\phi_{post}}{d\\mu_{post}} \\cdot \\frac{d\\mu_{post}}{dq} \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{d\\mathcal{L}}{d\\tau} = \\frac{1}{m}\\sum_{1=1}^{m}\\frac{d\\mathcal{L}}{d\\phi_{post}}\\cdot\\frac{d\\phi_{post}}{d\\tau}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{d\\mathcal{L}}{d\\Theta} = \\frac{1}{m}\\sum_{1=1}^{m}\\frac{d\\mathcal{L}}{d\\phi_{post}}\\cdot\\frac{\\partial\\phi_{post}}{\\partial\\mu_{post}}\\cdot \\frac{\\partial\\mu_{post}}{\\partial I}\\cdot \\frac{dI}{dd} \\cdot \\frac{dd}{d\\Theta}+\\frac{d\\mathcal{L}}{d\\phi_{post}}\\cdot\\frac{\\partial\\phi_{post}}{\\partial\\sigma_{post}}\\cdot \\frac{\\partial\\sigma_{post}}{\\partial I} \\cdot \\frac{\\partial I}{\\partial dd} \\cdot \\frac{dd}{d\\Theta}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gradients(X,grads,derivatives): \n",
    "    \n",
    "    n = X.shape[1]\n",
    "    B_grads = [0]*n\n",
    "    b_grads = 0\n",
    "    q_grads = 0\n",
    "    tau_grads = 0\n",
    "    sd_prior_grads = 0\n",
    "    theta_grads = 0\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        # Retrieve variables\n",
    "        dL_dphipost = derivatives['dL_dphi'][i]\n",
    "        dphipost_dmupost = derivatives['dphipost_dmupost'][i]\n",
    "        dphipost_dsdpost = derivatives['dphipost_dsdpost'][i]\n",
    "        dphipost_dtau = derivatives['dphipost_dtau'][i]\n",
    "        dmupost_dmuprior = derivatives['dmupost_dmuprior'][i]\n",
    "        dsdpost_dq = derivatives['dsdpost_dq'][i]\n",
    "        dmupost_dq = derivatives['dmupost_dq'][i]\n",
    "        dsdpost_dsdprior = derivatives['dsdpost_dsdprior'][i]\n",
    "        dmupost_dI = derivatives['dmupost_dI'][i]\n",
    "        dsdpost_dI = derivatives['dsdpost_dI'][i]\n",
    "        dI_dd = derivatives['dI_dd'][i]\n",
    "        dd_dmuprior = derivatives['dd_dmuprior'][i]\n",
    "        dd_dtheta = derivatives['dd_dtheta'][i]\n",
    "        x = X.iloc[i,:].tolist()\n",
    "\n",
    "        # dL_dB\n",
    "        B_grads = [sum(z) for z in zip(B_grads,np.dot(dL_dphipost*dphipost_dsdpost*dsdpost_dI*dI_dd*dd_dmuprior,x)+np.dot(dL_dphipost*dphipost_dmupost*dmupost_dmuprior,x)+np.dot(dL_dphipost*dphipost_dmupost*dmupost_dI*dI_dd*dd_dmuprior,x))]\n",
    "\n",
    "        # dL_db\n",
    "        b_grads += (dL_dphipost*dphipost_dsdpost*dsdpost_dI*dI_dd*dd_dmuprior*1) + (dL_dphipost*dphipost_dmupost*dmupost_dmuprior*1) + (dL_dphipost*dphipost_dmupost*dmupost_dI*dI_dd*dd_dmuprior*1)\n",
    "\n",
    "        #dL_dsdprior\n",
    "        sd_prior_grads += dL_dphipost*dphipost_dsdpost*dsdpost_dsdprior\n",
    "\n",
    "        # dL_dq\n",
    "        q_grads += (dL_dphipost*dphipost_dsdpost*dsdpost_dq) + (dL_dphipost*dphipost_dmupost*dmupost_dq)\n",
    "\n",
    "        # dL_dtau\n",
    "        tau_grads += dL_dphipost*dphipost_dtau\n",
    "        \n",
    "        # dL_dTheta\n",
    "        theta_grads += (dL_dphipost*dphipost_dmupost*dmupost_dI*dI_dd*dd_dtheta) + (dL_dphipost*dphipost_dsdpost*dsdpost_dI*dI_dd*dd_dtheta)\n",
    "    \n",
    "    grads['dB'] = [gr/float(len(X)) for gr in B_grads]\n",
    "    grads['db'] = b_grads/float(len(X))\n",
    "    grads['dsdprior'] = sd_prior_grads/float(len(X))\n",
    "    grads['dq'] = q_grads/float(len(X))\n",
    "    grads['dtau'] = tau_grads/float(len(X))\n",
    "    grads['dTheta'] = theta_grads/float(len(X))\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8) Update parameters with gradients**\n",
    "\n",
    "\\begin{equation}\n",
    "\\beta' = \\beta - \\alpha \\frac{d\\mathcal{L}}{d\\beta} \\\\\n",
    "b' = b - \\alpha \\frac{d\\mathcal{L}}{db} \\\\\n",
    "q' = q - \\alpha \\frac{d\\mathcal{L}}{dq} \\\\\n",
    "var_{prior}' = var_{prior}-\\alpha\\frac{d\\mathcal{L}}{dvar_{prior}} \\\\\n",
    "\\tau' = \\tau - \\alpha \\frac{dL}{d\\tau} \\\\\n",
    "\\Theta' = \\Theta - \\alpha \\frac{dL}{d\\Theta}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- dictionary containing updated parameters \n",
    "    \"\"\"\n",
    "    #parameters['B'] = np.array([(B-(learning_rate*gB)).tolist() for gB,B in zip(grads['dB'],parameters['B'])])\n",
    "    #parameters['b'] -= learning_rate*grads['db']\n",
    "    parameters['q'] -= learning_rate*grads['dq']\n",
    "    #parameters['sd_prior'] -= learning_rate*grads['dsdprior']\n",
    "    #parameters['tau'] -= learning_rate*grads['dtau']\n",
    "    #parameters['Theta'] -= learning_rate*grads['dTheta']\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_choice(X_test,risk_assess_test,best_params):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    \n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    mu_prior_test = calc_prior_mean(X_test, best_params)\n",
    "    mu_post_test = calc_post_mean(mu_prior_test, risk_assess_test, best_params)\n",
    "    sd_post_test =calc_post_sd(mu_prior_test, risk_assess_test, best_params)\n",
    "    y_test = calc_y(mu_post_test, sd_post_test, best_params)\n",
    "    \n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

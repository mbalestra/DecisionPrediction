# Predict judges' decisions when incorporating information from algorithmic risk assessment tool

Algorithmic risk assessment tools are increasingly being used as decision aids in a broad range of contexts. One of the most interesting and impactful applications is in pre-trial hearings, where they are increasingly being used to communicate the predicted likelihood that a defendant will re-offend or fail to appear at trial. The objective of this work is to build a predictive model of how judges make a decision conditional on exposure to such an algorithmic recommendation. A better understanding of how these decisions are made can help us to understand how bias propagates from the risk assessment algorithm to real-life decisions, and may eventually help us to design interventions that ‘nudge’ decision-makers towards making better, potentially more fair, decisions.

# Predict judges' decisions when incorporating information from algorithmic risk assessment tool

Algorithmic risk assessment tools are widely used as decision aids in a broad range of contexts. One of the most interesting and impactful applications is in pre-trial hearings, where they are increasingly used to communicate the predicted likelihood that a defendant will re-offend or fail to appear at trial. While a great deal of research has sought to understanding bias in these estimates of risk, fewer studies have centered on understanding how judges incorporate this information into their own internal estimate of a defendant’s risk. 

The objective of this work is to build a predictive model of a judge’s decision to release or remand a defendant as a function of how they update their own risk estimate once they have been exposed to the algorithmically-derived risk score. A better understanding of this updating process can help us to understand how bias propagates from the risk assessment algorithm into real-life decisions, and can reveal ways in which the algorithmically-derived risk assessment score can be tuned for a particular judge in order to elicit better, more fair decisions regarding a defendant.


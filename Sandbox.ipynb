{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "from ipynb.fs.full.GenerateData import generatedata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(X,lower,upper):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    X -- training data\n",
    "    lower -- lower bound of scale\n",
    "    upper -- upper bound of scale\n",
    "    \n",
    "    Returns:\n",
    "    params -- python dictionary containing model parameters:\n",
    "        B -- coefficient matrix\n",
    "        b -- constant\n",
    "        q -- constant\n",
    "        mu_var -- variance of prior \n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(212) \n",
    "    \n",
    "    # of parameters\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    B = np.random.rand(n,1)*0.1 # randomly initialize the B_0, B_1 coefficients\n",
    "    b = 0 # intialize  constants b,c @ 0\n",
    "    q = np.random.rand(1)*10\n",
    "    var = np.random.rand(1)*10\n",
    "    tau = random.randint(lower, upper)\n",
    "    \n",
    "    parameters = {\"B\": B,\n",
    "                  \"b\": b,\n",
    "                  \"q\" : q,\n",
    "                  \"var_prior\" : var,\n",
    "                  \"tau\" : tau}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_dicts(X,decile_score,z):\n",
    "    # Create dictionary to store data that is not being updated\n",
    "    cache = {\"mu_prior\" : [],\n",
    "         \"mu_ra\" : [],\n",
    "         \"var_ra\" : [],\n",
    "         \"mu_post\" : [],\n",
    "         \"var_post\" : []\n",
    "         }\n",
    "    cache['mu_ra'] = np.array(decile_score)\n",
    "\n",
    "    # create dictionary to store derivatives\n",
    "    derivatives = {\n",
    "        \"dL\": [],\n",
    "        \"dphipost_dmupost\": [],\n",
    "        \"dphipost_dvarpost\": [],\n",
    "        \"dphipost_dtau\": [],\n",
    "        \"dmuprior_dB\": [],\n",
    "        \"dmuprior_db\": [],\n",
    "        \"dmupost_dmuprior\": [],\n",
    "        \"dvarpost_dvarra\": [],\n",
    "        \"dvarra_dvarprior\": [],\n",
    "        \"dvarpost_dq\": [],\n",
    "        \"dmupost_dq\": [],\n",
    "        \"dvarra_dq\": [],\n",
    "        \"dvarpost_dvarprior\": []\n",
    "    }\n",
    "    \n",
    "    # create dictionary to store gradients\n",
    "    grads = {\n",
    "        \"dB\": [],\n",
    "        \"db\": [],\n",
    "        \"dq\": [],\n",
    "        \"dvar_dprior\": [],\n",
    "        \"dtau\" : []\n",
    "    }\n",
    "        \n",
    "    # initialize parameters\n",
    "    parameters = initialize_parameters(X,1,10)\n",
    "    \n",
    "    return cache, parameters, derivatives, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generatedata()\n",
    "\n",
    "# create dummy variables\n",
    "sex_dummies = pd.get_dummies(data['sex'])\n",
    "race_dummies = pd.get_dummies(data['race'])\n",
    "\n",
    "data['sex_1_male'] = sex_dummies['Male']\n",
    "data['African_American']=race_dummies['African-American']\n",
    "data['Asian']=race_dummies['Asian']\n",
    "data['Caucasian']=race_dummies['Caucasian']\n",
    "data['Hispanic'] = race_dummies['Hispanic']\n",
    "data['Native_American']=race_dummies['Native American']\n",
    "data['Other']=race_dummies['Other']\n",
    "\n",
    "# select out relevant data & generate the train and test data\n",
    "\n",
    "#data = data[['release','decile_score','age','is_violent_recid']] # NOTE::: This is just a subset of features we would examine in reality\n",
    "\n",
    "# train / test\n",
    "X = data[['release','decile_score','age','is_violent_recid']].drop(['release'],axis=1)\n",
    "y = data['release']\n",
    "class_names = data.release.unique()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=212)\n",
    "decile_score = X_train['decile_score']\n",
    "X_train = X_train.drop(['decile_score'],axis=1)\n",
    "\n",
    "#X_test = X_test.drop(['decile_score'],axis=1)\n",
    "\n",
    "cache,parameters,derivatives,grads = initialize_dicts(X_train,decile_score,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower=1\n",
    "upper=10\n",
    "theta = 5\n",
    "loss = []\n",
    "learning_rate = 0.1\n",
    "num_iterations = 5\n",
    "\n",
    "# of parameters\n",
    "n = X_train.shape[1]\n",
    "    \n",
    "B = np.random.rand(n,1)*0.1 # randomly initialize the B_0, B_1 coefficients\n",
    "b = 0 # intialize  constants b,c @ 0\n",
    "q = np.random.rand(1)*10\n",
    "var_prior = np.random.rand(1)*10\n",
    "tau = random.randint(lower, upper)\n",
    "mu_ra = np.array(decile_score)\n",
    "    \n",
    "# prior belief mean\n",
    "mu_prior = (np.dot(B.T,np.array(X_train).T)+b)[0]\n",
    "\n",
    "# risk assessment variance\n",
    "var_ra = np.array([q*var_prior if np.abs(mu_ra[i]-mu_prior[i])>theta else float(\"inf\") for i in range(len(mu_prior))])\n",
    "\n",
    "# posterior belief mean\n",
    "mu_post = np.array([(mu_prior[i]*(q/(q+1)))+(mu_ra[i]/(q+1)) if np.abs(mu_ra[i]-mu_prior[i])>theta else mu_prior[i] for i in range(len(mu_prior))])\n",
    "\n",
    "# posterior belief variance\n",
    "var_post = np.array([var_ra[i]*(q/(q+1)) if np.abs(mu_ra[i]-mu_prior[i])>theta else var_prior for i in range(len(var_ra))])\n",
    "\n",
    "Phi = []\n",
    "for i in range(len(mu_post)):\n",
    "    posterior = scipy.stats.norm(loc=mu_post[i],scale=np.sqrt(var_post[i]))\n",
    "    Phi.append(1 - posterior.cdf(tau))\n",
    "\n",
    "# some pred_y = 0 or 1 due to rounding in pythong, which produces an error when take log; add a tiny little number to get around this.\n",
    "Phi = [1e-16 if i==0 else i for i in Phi]\n",
    "Phi = np.array([1-1e-16 if i==1 else i for i in Phi])\n",
    "\n",
    "# calculate loss\n",
    "L = (-np.array(y_train)*np.log(Phi))-(1-np.array(y_train))*np.log(1-np.array(Phi))\n",
    "loss.append(np.sum(L))\n",
    "\n",
    "# Calculate Derivatives / Partial Derivatives\n",
    "\n",
    "# dL\n",
    "post_normal = scipy.stats.norm(mu_post,np.sqrt(var_post))\n",
    "phi_post = post_normal.pdf(tau)\n",
    "\n",
    "dL = phi_post*((np.array(1-y_train)*(phi_post/Phi))-(np.array(y_train)*(phi_post/(1-Phi))))\n",
    "\n",
    "# dphi_post / dmu_post\n",
    "dphipost_dmupost = ((tau-mu_post)/((var_post**(3/2))*((2*math.pi)**(1/2))))*np.exp((-((tau-mu_post)**2 / (2*var_post))).astype(float))\n",
    "\n",
    "# dphi_post / dvar_post\n",
    "dphipost_dvarpost = ((((tau-mu_post)**2)/(2*(var_post**(5/2))*((2*math.pi)**(1/2))))-(1/(2*(var_post**(3/2))*((2*math.pi)**(1/2)))))*np.exp(((-(((tau-mu_post)**2)/(2*var_post)))).astype(float))\n",
    "\n",
    "#dphi_post / dtau\n",
    "dphipost_dtau = derivatives['dphipost_dtau'] = (-((tau-mu_post)/((var_post**(3/2))*((2*math.pi)**(1/2)))))*np.exp((-(((tau-mu_post)**2)/(2*var_post))))\n",
    "\n",
    "dmupost_dmuprior = []\n",
    "dvarpost_dvarra = []\n",
    "dvarra_dvarprior = []\n",
    "dvarpost_dq = []\n",
    "dmupost_dq = []\n",
    "dvarra_dq = []\n",
    "dvarpost_dvarprior = []\n",
    "\n",
    "for i in range(len(mu_prior)):\n",
    "    if np.abs(mu_prior[i] - mu_ra[i]) > theta:\n",
    "        # dmu_post/dmu_prior\n",
    "        dmupost_dmuprior.append((q/(q+1)))\n",
    "\n",
    "        # dvarpost / dvarra\n",
    "        dvarpost_dvarra.append((q/(q+1)))\n",
    "\n",
    "        # dvarra / dvarprior\n",
    "        dvarra_dvarprior.append(q)\n",
    "\n",
    "        #dvarpost_dq\n",
    "        dvarpost_dq.append(((var_ra[i]/(q+1))+((q*var_ra[i])/(q+1)**2)))\n",
    "\n",
    "        #dmupost_dq\n",
    "        dmupost_dq.append((mu_prior[i]/(q+1)) - (mu_ra[i]/((q+1)**2)) - ((mu_prior[i]*q)/((q+1)**2)))\n",
    "\n",
    "        #dvarra_dq\n",
    "        dvarra_dq.append((var_prior**2))\n",
    "\n",
    "        #dvarpost_dvarprior\n",
    "        dvarpost_dvarprior.append(0)\n",
    "    else:\n",
    "        # dmu_post/dmu_prior\n",
    "        dmupost_dmuprior.append(1)\n",
    "\n",
    "        # dvarpost / dvarra\n",
    "        dvarpost_dvarra.append(0)\n",
    "\n",
    "        # dvarra / dvarprior\n",
    "        dvarra_dvarprior.append(0)\n",
    "\n",
    "        #dvarpost_dq\n",
    "        dvarpost_dq.append(0)\n",
    "\n",
    "        #dmupost_dq\n",
    "        dmupost_dq.append(0)\n",
    "\n",
    "        #dvarra_dq\n",
    "        dvarra_dq.append(0)\n",
    "\n",
    "        #dvarpost_dvarprior\n",
    "        dvarpost_dvarprior.append(1)\n",
    "\n",
    "# Calculate gradients\n",
    "\n",
    "# dL_dB\n",
    "dB = np.dot(dL*dphipost_dmupost*dmupost_dmuprior,X_train)\n",
    "\n",
    "\n",
    "# dL_db\n",
    "db = np.sum(dL*((dphipost_dmupost*dmupost_dmuprior)))\n",
    "\n",
    "#dL_dvarprior\n",
    "dvar_dprior = np.sum(dL*(dphipost_dvarpost*dvarpost_dvarra*dvarra_dvarprior+dphipost_dvarpost*dvarpost_dvarprior))         \n",
    "\n",
    "# dL_dq\n",
    "dq = grads['dq'] = np.sum(dL*(dphipost_dvarpost*dvarpost_dq+dphipost_dmupost*dmupost_dq+dphipost_dvarpost*dvarpost_dvarra*dvarra_dq))\n",
    "\n",
    "# dL_dtau\n",
    "dtau = np.sum(dL*dphipost_dtau)\n",
    "\n",
    "B = np.array([B[i]-(dB[i]*learning_rate) for i in range(B.shape[0])])\n",
    "b = b-(learning_rate*db)\n",
    "q = q-(learning_rate*dq)\n",
    "var_prior = var_prior-(learning_rate*dvar_dprior)\n",
    "tau = tau-(learning_rate*dtau)\n",
    "\n",
    "    #j+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B': array([[0.02329016],\n",
       "        [0.09116896]]),\n",
       " 'b': 0,\n",
       " 'q': array([0.51030257]),\n",
       " 'var_prior': array([0.1000737]),\n",
       " 'tau': 4}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mu_prior': [],\n",
       " 'mu_ra': array([2, 2, 3, ..., 7, 3, 6]),\n",
       " 'var_ra': [],\n",
       " 'mu_post': [],\n",
       " 'var_post': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'exp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1a80c3aa563a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmu_post\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_post\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmu_post\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvar_post\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mdphipost_dtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderivatives\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dphipost_dtau'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# dmu_prior / dB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'exp'"
     ]
    }
   ],
   "source": [
    "theta = 5\n",
    "loss = []\n",
    "learning_rate = 0.1\n",
    "num_iterations = 3\n",
    "\n",
    "j=0\n",
    "\n",
    "while j<num_iterations:\n",
    "    \n",
    "    B=parameters['B']\n",
    "    b=parameters['b']\n",
    "    var_prior = parameters['var_prior']\n",
    "    mu_ra = cache['mu_ra']\n",
    "    q = parameters['q']\n",
    "    tau = parameters['tau']\n",
    "\n",
    "    # prior belief mean\n",
    "    mu_prior = cache['mu_prior'] = (np.dot(B.T,np.array(X_train).T)+b)[0]\n",
    "\n",
    "    # risk assessment variance\n",
    "    var_ra = cache['var_ra'] = np.array([q*var_prior if np.abs(mu_ra[i]-mu_prior[i])>theta else float(\"inf\") for i in range(len(mu_prior))])\n",
    "\n",
    "    # posterior belief mean\n",
    "    mu_post = cache['mu_post'] = np.array([(mu_prior[i]*(q/(q+1)))+(mu_ra[i]/(q+1)) if np.abs(mu_ra[i]-mu_prior[i])>theta else mu_prior[i] for i in range(len(mu_prior))])\n",
    "\n",
    "    # posterior belief variance\n",
    "    var_post = cache['var_post'] = np.array([var_ra[i]*(q/(q+1)) if np.abs(mu_ra[i]-mu_prior[i])>theta else var_prior for i in range(len(var_ra))])\n",
    "\n",
    "    Phi = []\n",
    "    for i in range(len(mu_post)):\n",
    "        posterior = scipy.stats.norm(loc=mu_post[i],scale=np.sqrt(var_post[i]))\n",
    "        Phi.append(1 - posterior.cdf(tau))\n",
    "\n",
    "    # some pred_y = 0 or 1 due to rounding in pythong, which produces an error when take log; add a tiny little number to get around this.\n",
    "    Phi = [1e-16 if i==0 else i for i in Phi]\n",
    "    Phi = np.array([1-1e-16 if i==1 else i for i in Phi])\n",
    "\n",
    "    # calculate loss\n",
    "    L = (-np.array(y_train)*np.log(Phi.astype('float64')))-(1-np.array(y_train))*np.log(1-Phi.astype('float64'))\n",
    "    loss.append(np.sum(L))\n",
    "\n",
    "    # Calculate Derivatives / Partial Derivatives\n",
    "\n",
    "    # dL\n",
    "    post_normal = scipy.stats.norm(mu_post,np.sqrt(var_post))\n",
    "    phi_post = post_normal.pdf(tau)\n",
    "\n",
    "    dL = derivatives['dL'] = phi_post*((np.array(1-y_train)*(phi_post/Phi))-(np.array(y_train)*(phi_post/(1-Phi))))\n",
    "\n",
    "    # dphi_post / dmu_post\n",
    "    p1 = (tau-mu_post)/((var_post**(3/2))*((2*math.pi)**(1/2)))\n",
    "    p2 = -((tau-mu_post)**2 / (2*var_post))\n",
    "    dphipost_dmupost = derivatives['dphipost_dmupost'] = p1*np.exp(p2.astype(float))\n",
    "\n",
    "    # dphi_post / dvar_post\n",
    "    p1 = ((tau-mu_post)**2)/(2*(var_post**(5/2))*((2*math.pi)**(1/2)))\n",
    "    p2 = 1/(2*(var_post**(3/2))*((2*math.pi)**(1/2)))\n",
    "    p3 = (-(((tau-mu_post)**2)/(2*var_post)))\n",
    "    dphipost_dvarpost = derivatives['dphipost_dvarpost'] = (p1-p2)*np.exp(p3.astype(float))\n",
    "\n",
    "    #dphi_post / dtau\n",
    "    p1 = -((tau-mu_post)/((var_post**(3/2))*((2*math.pi)**(1/2))))\n",
    "    p2 = -(((tau-mu_post)**2)/(2*var_post))\n",
    "    dphipost_dtau = derivatives['dphipost_dtau'] = p1*np.exp(p2)\n",
    "\n",
    "    # dmu_prior / dB\n",
    "    #derivatives['dmuprior_dB'] = X\n",
    "\n",
    "    # dmu_prior / db\n",
    "    #derivatives['dmuprior_db'] = 1\n",
    "\n",
    "    dmupost_dmuprior = []\n",
    "    dvarpost_dvarra = []\n",
    "    dvarra_dvarprior = []\n",
    "    dvarpost_dq = []\n",
    "    dmupost_dq = []\n",
    "    dvarra_dq = []\n",
    "    dvarpost_dvarprior = []\n",
    "\n",
    "    for i in range(len(mu_prior)):\n",
    "        if np.abs(mu_prior[i] - mu_ra[i]) > theta:\n",
    "            # dmu_post/dmu_prior\n",
    "            dmupost_dmuprior.append((q/(q+1)))\n",
    "\n",
    "            # dvarpost / dvarra\n",
    "            dvarpost_dvarra.append((q/(q+1)))\n",
    "\n",
    "            # dvarra / dvarprior\n",
    "            dvarra_dvarprior.append(q)\n",
    "\n",
    "            #dvarpost_dq\n",
    "            dvarpost_dq.append(((var_ra[i]/(q+1))+((q*var_ra[i])/(q+1)**2)))\n",
    "\n",
    "            #dmupost_dq\n",
    "            dmupost_dq.append((mu_prior[i]/(q+1)) - (mu_ra[i]/((q+1)**2)) - ((mu_prior[i]*q)/((q+1)**2)))\n",
    "\n",
    "            #dvarra_dq\n",
    "            dvarra_dq.append((var_prior**2))\n",
    "\n",
    "            #dvarpost_dvarprior\n",
    "            dvarpost_dvarprior.append(0)\n",
    "        else:\n",
    "            # dmu_post/dmu_prior\n",
    "            dmupost_dmuprior.append(1)\n",
    "\n",
    "            # dvarpost / dvarra\n",
    "            dvarpost_dvarra.append(0)\n",
    "\n",
    "            # dvarra / dvarprior\n",
    "            dvarra_dvarprior.append(0)\n",
    "\n",
    "            #dvarpost_dq\n",
    "            dvarpost_dq.append(0)\n",
    "\n",
    "            #dmupost_dq\n",
    "            dmupost_dq.append(0)\n",
    "\n",
    "            #dvarra_dq\n",
    "            dvarra_dq.append(0)\n",
    "\n",
    "            #dvarpost_dvarprior\n",
    "            dvarpost_dvarprior.append(1)\n",
    "\n",
    "    derivatives['dmupost_dmuprior'] = np.array(dmupost_dmuprior)\n",
    "    derivatives['dvarpost_dvarra'] = np.array(dvarpost_dvarra)\n",
    "    derivatives['dvarra_dvarprior'] = np.array(dvarra_dvarprior)\n",
    "    derivatives['dvarpost_dq'] = np.array(dvarpost_dq)\n",
    "    derivatives['dmupost_dq'] = np.array(dmupost_dq)\n",
    "    derivatives['dvarra_dq'] = np.array(dvarra_dq)\n",
    "    derivatives['dvarpost_dvarprior'] = np.array(dvarpost_dvarprior)\n",
    "\n",
    "    # Calculate gradients\n",
    "\n",
    "    # dL_dB\n",
    "    dB = grads['dB'] = np.dot(dL*dphipost_dmupost*dmupost_dmuprior,X_train)\n",
    "\n",
    "    # dL_db\n",
    "    db = grads['db'] = np.sum(dL*((dphipost_dmupost*dmupost_dmuprior)))\n",
    "\n",
    "    #dL_dvarprior\n",
    "    dvar_dprior = grads['dvar_dprior'] = np.sum(dL*(dphipost_dvarpost*dvarpost_dvarra*dvarra_dvarprior+dphipost_dvarpost*dvarpost_dvarprior))         \n",
    "\n",
    "    # dL_dq\n",
    "    dq = grads['dq'] = np.sum(dL*(dphipost_dvarpost*dvarpost_dq+dphipost_dmupost*dmupost_dq+dphipost_dvarpost*dvarpost_dvarra*dvarra_dq))\n",
    "\n",
    "    # dL_dtau\n",
    "    dtau = grads['dtau'] = np.sum(dL*dphipost_dtau)\n",
    "\n",
    "    parameters['B'] = np.array([B[i]-(dB[i]*learning_rate) for i in range(B.shape[0])])\n",
    "    parameters['b'] = b-(learning_rate*db)\n",
    "    parameters['q'] = q-(learning_rate*dq)\n",
    "    parameters['var_prior'] = var_prior-(learning_rate*dvar_dprior)\n",
    "    parameters['tau'] = tau-(learning_rate*dtau)\n",
    "\n",
    "    #j+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recalculate risk assessment variance\n",
    "var_ra = cache['var_ra'] = np.array([q*var_prior if np.abs(mu_ra[i]-mu_prior[i])>theta else float(\"inf\") for i in range(len(mu_prior))])\n",
    "var_ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "from operator import add\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import roc_auc_score,roc_curve, auc\n",
    "\n",
    "from ipynb.fs.full.GenerateData import generatedata\n",
    "from ipynb.fs.full.AnalysisPartFunctions import initialize_parameters,initialize_dicts,calc_prior_mean,calc_post_mean,calc_post_sd,calc_Phi,calc_L,calc_component_derivs,calc_gradients,update_parameters, predict_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Generate data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(generatedata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check how many released/remanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.release.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Create dummy variables for categorical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_dummies = pd.get_dummies(data['sex'])\n",
    "race_dummies = pd.get_dummies(data['race'])\n",
    "age_dummies = pd.get_dummies(data['age_cat'])\n",
    "\n",
    "data['sex_1_male'] = sex_dummies['Male']\n",
    "data['African_American']=race_dummies['African-American']\n",
    "data['Asian']=race_dummies['Asian']\n",
    "data['Caucasian']=race_dummies['Caucasian']\n",
    "data['Hispanic'] = race_dummies['Hispanic']\n",
    "data['Native_American']=race_dummies['Native American']\n",
    "data['race_Other']=race_dummies['Other']\n",
    "data['Greater_45']=age_dummies['Greater than 45']\n",
    "data['25_45']=age_dummies['25 - 45']\n",
    "data['Less_25']=age_dummies['Less than 25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Split data into training & test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select out relevant data & generate the train and test data\n",
    "\n",
    "# train / test\n",
    "features = ['decile_score','Less_25','25_45','Greater_45','sex_1_male','African_American','Caucasian','is_violent_recid','juv_fel_count']\n",
    "X = data[features]\n",
    "y = data['release']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=120)\n",
    "\n",
    "risk_assess_train = X_train['decile_score']\n",
    "X_train = X_train.drop(['decile_score'],axis=1)\n",
    "\n",
    "risk_assess_test = X_test['decile_score'].tolist()\n",
    "X_test = X_test.drop(['decile_score'],axis=1)\n",
    "y_test = y_test.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables for analysis without penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_parameters = initialize_parameters(X_train,1,10)\n",
    "derivatives,grads = initialize_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\"B\": initial_parameters['B'],\n",
    "              \"b\": initial_parameters['b'],\n",
    "              \"q\" : initial_parameters['q'],\n",
    "              \"sd_prior\" : initial_parameters['sd_prior'],\n",
    "              \"tau\" : initial_parameters['tau']}\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train\n",
    "Y = y_train.tolist()\n",
    "mu_ra = risk_assess_train.tolist()\n",
    "num_int = 10\n",
    "#learning_rate = 0.2\n",
    "Theta = list(range(0,1))\n",
    "\n",
    "# create containers for the optimized parameters for each \n",
    "param_info = {}\n",
    "for i in range(len(Theta)):\n",
    "    th = Theta[i]\n",
    "    param_info[th]={}\n",
    "    param_info[th]['auc']=[]\n",
    "    param_info[th]['loss']=[]\n",
    "    param_info[th]['learn_rate']=[]\n",
    "    param_info[th]['best_params']={}\n",
    "    param_info[th]['best_params']['B']=[0]*X.shape[1]\n",
    "    param_info[th]['best_params']['b']=0\n",
    "    param_info[th]['best_params']['q']=0\n",
    "    param_info[th]['best_params']['sd_prior']=0\n",
    "    param_info[th]['best_params']['tau']=0\n",
    "\n",
    "# learn model\n",
    "for theta in Theta: \n",
    "    \n",
    "    # reset the 'parameters' dict to the initial parameters values\n",
    "    parameters = {\"B\": initial_parameters['B'],\n",
    "                  \"b\": initial_parameters['b'],\n",
    "                  \"q\" : initial_parameters['q'],\n",
    "                  \"sd_prior\" : initial_parameters['sd_prior'],\n",
    "                  \"tau\" : initial_parameters['tau']}\n",
    "    \n",
    "    loss = []\n",
    "    learning_rate = []\n",
    "    j = 0\n",
    "    prev_L = 0 \n",
    "    init_lr = 0.001\n",
    "\n",
    "    #print(\"params: \",parameters)\n",
    "    \n",
    "    while j < num_int:\n",
    "        mu_prior = calc_prior_mean(X, parameters)\n",
    "        mu_post = calc_post_mean(mu_prior, mu_ra, parameters, theta)\n",
    "        sd_post =calc_post_sd(mu_prior, mu_ra, parameters, theta)\n",
    "        Phi = calc_Phi(mu_post, sd_post, parameters)\n",
    "        L = calc_L(Phi, Y)\n",
    "        loss.append(L)\n",
    "        \n",
    "        # set learning rate: if loss is negative double learning rate; else halve learning rate\n",
    "        if j==0:\n",
    "            lr=init_lr\n",
    "        elif j>0 and prev_L>L:\n",
    "            lr = lr*2\n",
    "        else:\n",
    "            lr = lr/2\n",
    "        \n",
    "        learning_rate.append(lr)\n",
    "        \n",
    "        derivatives = calc_component_derivs(X,parameters, derivatives, theta, mu_prior,mu_ra,mu_post,sd_post,Phi,Y)\n",
    "        grads = calc_gradients(X,grads,derivatives)\n",
    "        parameters = update_parameters(parameters, grads, lr)\n",
    "        prev_L = L\n",
    "        #print(\"intermediate params: \",parameters)\n",
    "        \n",
    "        # print loss so we can track the progress of the model\n",
    "        if j%1==0:\n",
    "            print(\"loss: \",L)\n",
    "        j+=1\n",
    "    \n",
    "    param_info[theta]['loss'] = loss\n",
    "    param_info[theta]['learn_rate'] = learning_rate\n",
    "    #print(\"optim params: \", parameters)\n",
    "    \n",
    "    # test these parameters to calculate auc and compare to others\n",
    "    Phi_test = predict_choice(X_test,risk_assess_test,parameters,theta)\n",
    "    \n",
    "    # calculate the auc with the converged weights\n",
    "    auc = roc_auc_score(y_test,Phi_test)\n",
    "    param_info[theta]['auc'] = auc\n",
    "    #print(\"auc: \",auc)\n",
    "    \n",
    "    # if there is an improvement in the AUC, update the 'best_params' with those weights\n",
    "    param_info[theta]['best_params']['B'] = parameters['B']\n",
    "    param_info[theta]['best_params']['b'] = parameters['b']\n",
    "    param_info[theta]['best_params']['q'] = parameters['q']\n",
    "    param_info[theta]['best_params']['sd_prior'] = parameters['sd_prior']\n",
    "    param_info[theta]['best_params']['tau'] = parameters['tau']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot loss over theta\n",
    "for i in param_info:\n",
    "    plt.plot(param_info[i]['loss'],label='theta = %s' % (i))\n",
    "    plt.xlim([0.0, 10.0])\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in param_info:\n",
    "    y_pred = predict_choice(X_test,risk_assess_test,param_info[i]['best_params'],best_theta=i)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    plt.plot(fpr, tpr, lw=lw, label='ROC curve (area = %0.2f, theta = %s)' % (roc_auc,i))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mu_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "parameters = {'B': array([[0.07177631],\n",
    "        [0.07214579],\n",
    "        [0.02697002],\n",
    "        [0.03161949],\n",
    "        [0.02467784],\n",
    "        [0.03341922],\n",
    "        [0.07176589],\n",
    "        [0.08871475]]),\n",
    " 'b': 7.037519546355625,\n",
    " 'q': 0.30325946457835395,\n",
    " 'sd_prior': 3.313766807141957,\n",
    " 'tau': 9}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables for analysis with penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = initialize_parameters(X_test,1,10)\n",
    "derivatives,grads = initialize_dicts()\n",
    "\n",
    "X = X_train\n",
    "y = np.array(y_train)\n",
    "mu_ra = np.array(risk_assess_train)\n",
    "theta = 5\n",
    "num_int = 100\n",
    "learning_rate = 0.001\n",
    "k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = []\n",
    "j = 0\n",
    "\n",
    "while j < num_int:\n",
    "    \n",
    "    var_prior = parameters['var_prior'][0]\n",
    "    q = parameters['q'][0]\n",
    "    tau = parameters['tau']\n",
    "        \n",
    "    mu_prior = calc_prior_mean(X, parameters)[0]\n",
    "    mu_post = calc_post_mean(mu_prior, mu_ra, q, theta)\n",
    "    var_post = calc_post_var(mu_prior, mu_ra, var_prior, q, theta)\n",
    "    Phi = calc_Phi(mu_post, var_post, tau)\n",
    "    L = calc_L(Phi, y, mu_prior, k)\n",
    "    loss.append(np.sum(L))\n",
    "        \n",
    "    if j%%5==0:\n",
    "        print(L)\n",
    "        \n",
    "    derivatives = calc_component_derivs(X, y, parameters, derivatives, theta, mu_prior, mu_ra, mu_post, var_post, Phi, k)\n",
    "    grads = calc_gradients(grads, derivatives, mu_prior, X)\n",
    "    parameters = update_parameters(parameters, grads, learning_rate)\n",
    "    \n",
    "    j+=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = []\n",
    "\n",
    "var_prior = parameters['var_prior'][0]\n",
    "q = parameters['q'][0]\n",
    "tau = parameters['tau']\n",
    "\n",
    "mu_prior = calc_prior_mean(X, parameters)[0]\n",
    "mu_post = calc_post_mean(mu_prior, mu_ra, q, theta)\n",
    "var_post = calc_post_var(mu_prior, mu_ra, var_prior, q, theta)\n",
    "Phi = calc_Phi(mu_post, var_post, tau)\n",
    "L = calc_L(Phi, y, mu_prior, k)\n",
    "loss.append(np.sum(L))\n",
    "        \n",
    "derivatives = calc_component_derivs(X, y, parameters, derivatives, theta, mu_prior, mu_ra, mu_post, var_post, Phi, k)\n",
    "grads = calc_gradients(grads, derivatives, mu_prior, X)\n",
    "parameters = update_parameters(parameters, grads, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"B: \",parameters['B'])\n",
    "print(\"b: \",parameters['b'])\n",
    "print(\"q: \",parameters['q'])\n",
    "print(\"var_prior: \",parameters['var_prior'])\n",
    "print(\"tau: \",parameters['tau'])\n",
    "print(\"loss: \",loss)\n",
    "print(\"mu_prior: \",np.min(mu_prior),\"to\",np.max(mu_prior))\n",
    "print(\"mu_post: \",np.min(mu_post),\"to\",np.max(mu_post))\n",
    "print(\"Phi: \", np.min(Phi),\"to\",np.max(Phi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_prior = parameters['var_prior'][0]\n",
    "q = parameters['q'][0]\n",
    "tau = parameters['tau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_prior = calc_prior_mean(X, parameters)[0]\n",
    "mu_post = calc_post_mean(mu_prior, mu_ra, q, theta)\n",
    "var_post = calc_post_var(mu_prior, mu_ra, var_prior, q, theta)\n",
    "Phi = calc_Phi(mu_post, var_post, tau)\n",
    "L = calc_L(Phi, y, mu_prior, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = 10*((1-mu_prior)**3)\n",
    "test2 = y_train*np.log(1-Phi)+(1-y)*np.log(Phi)\n",
    "test = test1 + test2\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.append(np.sum(L))\n",
    "        \n",
    "derivatives = calc_component_derivs(X, y, parameters, derivatives, theta, mu_prior, mu_ra, mu_post, var_post, Phi, k)\n",
    "grads = calc_gradients(grads, derivatives, mu_prior, X)\n",
    "parameters = update_parameters(parameters, grads, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Predict test/train set examples \n",
    "#y_pred_train = predict(parameters,X_train,y_train,risk_assess_train,theta=5)\n",
    "#y_pred_test = predict(parameters,X_test,y_test,risk_assess_test,theta=5)\n",
    "\n",
    "# Print train/test Errors\n",
    "# general accuracy\n",
    "print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_pred_train - y_train)) * 100))\n",
    "print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_pred_test - y_test)) * 100))\n",
    "\n",
    "# confusion matrix\n",
    "confmat = []\n",
    "\n",
    "for true,pred in zip(y_train,y_pred_train):\n",
    "    if(true==1 and pred==1):\n",
    "        confmat.append(\"tp\")\n",
    "    elif(true==1 and pred==0):\n",
    "        confmat.append(\"fn\")\n",
    "    elif(true==0 and pred==0):\n",
    "        confmat.append(\"tn\")\n",
    "    else:\n",
    "        confmat.append(fp)\n",
    "\n",
    "print(\"true positives: \",confmat.count('tp'))\n",
    "print(\"false positives: \",confmat.count('fp'))\n",
    "print(\"true negatives: \",confmat.count('tn'))\n",
    "print(\"false negatives: \",confmat.count('fn'))\n",
    "\n",
    "if (confmat.count('tp')+confmat.count('fn'))>0:\n",
    "    print(\"sensitivity/recall: \",confmat.count('tp')/(confmat.count('tp')+confmat.count('fn')))\n",
    "else:\n",
    "    print(\"sensitivity/recall: N/A\")\n",
    "    \n",
    "if (confmat.count('tn')+confmat.count('fp'))>0:\n",
    "    print(\"specificity: \",confmat.count('tn')/(confmat.count('tn')+confmat.count('fp')))\n",
    "else:\n",
    "    print(\"specificity: N/A\")\n",
    "    \n",
    "if (confmat.count('tp')+confmat.count('fp'))>0:\n",
    "    print(\"precision: \",confmat.count('tp')/(confmat.count('tp')+confmat.count('fp')))\n",
    "else:\n",
    "    print(\"precision: N/A\")\n",
    "    \n",
    "model_dict = {\"nLL\": L,\n",
    "              \"y_pred_test\": y_pred_test,\n",
    "              \"y_pred_train\" : y_pred_train,\n",
    "              \"parameters\" : parameters\n",
    "              \"learning_rate\" : learning_rate,\n",
    "              \"num_iterations\": num_iterations}\n",
    "\n",
    "#return model_dict\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(X,y,parameters,mu_ra,theta,num_int,learning_rate,k):\n",
    "    \n",
    "    mu_ra = np.array(mu_ra)\n",
    "    y=np.array(y)\n",
    "    loss = []\n",
    "    j = 0\n",
    "    \n",
    "    while j < num_int:\n",
    "        \n",
    "        var_prior = parameters['var_prior'][0]\n",
    "        q = parameters['q'][0]\n",
    "        tau = parameters['tau']\n",
    "        \n",
    "        mu_prior = calc_prior_mean(X, parameters)[0]\n",
    "        mu_post = calc_post_mean(mu_prior, mu_ra, q, theta)\n",
    "        var_post = calc_post_var(mu_prior, mu_ra, var_prior, q, theta)\n",
    "        Phi = calc_Phi(mu_post, var_post, tau)\n",
    "        L = calc_L(Phi, y, mu_prior, k)\n",
    "        loss.append(np.sum(L))\n",
    "        \n",
    "        derivatives = calc_component_derivs(X, parameters, theta, mu_prior, mu_ra, mu_post, var_post, Phi, k)\n",
    "        grads = calc_gradients(derivatives, mu_prior, X)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        #print(parameters)\n",
    "        j+=1\n",
    "        \n",
    "    return loss, parameters, derivatives, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters,X,y,risk_assess,theta):\n",
    "    \n",
    "    tau = parameters['tau']\n",
    "    q = parameters['q']\n",
    "    mu_ra = np.array(risk_assess)\n",
    "    mu_prior = calc_prior_mean(X,parameters)[0]\n",
    "    var_prior = parameters['var_prior']\n",
    "    #var_ra = calc_var_ra(var_prior,mu_prior,mu_ra,q,theta)\n",
    "    \n",
    "    mu_post = calc_post_mean(mu_prior, mu_ra, q, theta)\n",
    "    var_post = calc_post_var(mu_prior, mu_ra, var_prior, q, theta)\n",
    "    Phi = calc_Phi(mu_post,var_post,tau)\n",
    "    #L = calc_L(Phi,y)\n",
    "    \n",
    "    y_pred = [1 if Phi[i]>0.5 else 0 for i in range(len(Phi))]\n",
    "    \n",
    "    return y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

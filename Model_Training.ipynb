{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "from operator import add\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import roc_auc_score,roc_curve, auc\n",
    "\n",
    "from ipynb.fs.full.GenerateData import generatedata\n",
    "from ipynb.fs.full.AnalysisPartFunctions import initialize_parameters,initialize_dicts,calc_prior_mean,calc_post_mean,calc_post_sd,calc_Phi,calc_L,calc_component_derivs,calc_gradients,update_parameters, predict_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Generate data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(generatedata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>...</th>\n",
       "      <th>r_charge_desc</th>\n",
       "      <th>r_jail_in</th>\n",
       "      <th>r_jail_out</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>num_vr_cases</th>\n",
       "      <th>vr_case_number</th>\n",
       "      <th>vr_charge_degree</th>\n",
       "      <th>vr_offense_date</th>\n",
       "      <th>vr_charge_desc</th>\n",
       "      <th>release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>1947-04-18 00:00:00.000000</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>michael ryan</td>\n",
       "      <td>michael</td>\n",
       "      <td>ryan</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1985-02-06 00:00:00.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1982-01-22 00:00:00.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>...</td>\n",
       "      <td>Felony Battery (Dom Strang)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13009779CF10A</td>\n",
       "      <td>(F3)</td>\n",
       "      <td>2013-07-05 00:00:00.000000</td>\n",
       "      <td>Felony Battery (Dom Strang)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1991-05-14 00:00:00.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>...</td>\n",
       "      <td>Driving Under The Influence</td>\n",
       "      <td>2013-06-16 09:05:47.000000</td>\n",
       "      <td>2013-06-16 07:18:55.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1993-01-21 00:00:00.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  id              name    first       last   sex              race  \\\n",
       "0      0   1  miguel hernandez   miguel  hernandez  Male             Other   \n",
       "1      1   2      michael ryan  michael       ryan  Male         Caucasian   \n",
       "2      2   3       kevon dixon    kevon      dixon  Male  African-American   \n",
       "3      3   4          ed philo       ed      philo  Male  African-American   \n",
       "4      4   5       marcu brown    marcu      brown  Male  African-American   \n",
       "\n",
       "                          dob  age          age_cat  ...  \\\n",
       "0  1947-04-18 00:00:00.000000   69  Greater than 45  ...   \n",
       "1  1985-02-06 00:00:00.000000   31          25 - 45  ...   \n",
       "2  1982-01-22 00:00:00.000000   34          25 - 45  ...   \n",
       "3  1991-05-14 00:00:00.000000   24     Less than 25  ...   \n",
       "4  1993-01-21 00:00:00.000000   23     Less than 25  ...   \n",
       "\n",
       "                 r_charge_desc                   r_jail_in  \\\n",
       "0                          NaN                         NaN   \n",
       "1                          NaN                         NaN   \n",
       "2  Felony Battery (Dom Strang)                         NaN   \n",
       "3  Driving Under The Influence  2013-06-16 09:05:47.000000   \n",
       "4                          NaN                         NaN   \n",
       "\n",
       "                   r_jail_out is_violent_recid  num_vr_cases  vr_case_number  \\\n",
       "0                         NaN                0           NaN             NaN   \n",
       "1                         NaN                0           NaN             NaN   \n",
       "2                         NaN                1           NaN   13009779CF10A   \n",
       "3  2013-06-16 07:18:55.000000                0           NaN             NaN   \n",
       "4                         NaN                0           NaN             NaN   \n",
       "\n",
       "   vr_charge_degree             vr_offense_date               vr_charge_desc  \\\n",
       "0               NaN                         NaN                          NaN   \n",
       "1               NaN                         NaN                          NaN   \n",
       "2              (F3)  2013-07-05 00:00:00.000000  Felony Battery (Dom Strang)   \n",
       "3               NaN                         NaN                          NaN   \n",
       "4               NaN                         NaN                          NaN   \n",
       "\n",
       "  release  \n",
       "0       1  \n",
       "1       0  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check how many released/remanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6800\n",
       "0    4942\n",
       "Name: release, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.release.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Create dummy variables for categorical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_dummies = pd.get_dummies(data['sex'])\n",
    "race_dummies = pd.get_dummies(data['race'])\n",
    "age_dummies = pd.get_dummies(data['age_cat'])\n",
    "\n",
    "data['sex_1_male'] = sex_dummies['Male']\n",
    "data['African_American']=race_dummies['African-American']\n",
    "data['Asian']=race_dummies['Asian']\n",
    "data['Caucasian']=race_dummies['Caucasian']\n",
    "data['Hispanic'] = race_dummies['Hispanic']\n",
    "data['Native_American']=race_dummies['Native American']\n",
    "data['race_Other']=race_dummies['Other']\n",
    "data['Greater_45']=age_dummies['Greater than 45']\n",
    "data['25_45']=age_dummies['25 - 45']\n",
    "data['Less_25']=age_dummies['Less than 25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'id', 'name', 'first', 'last', 'sex', 'race', 'dob', 'age',\n",
       "       'age_cat', 'juv_fel_count', 'juv_misd_count', 'juv_other_count',\n",
       "       'compas_screening_date', 'decile_score', 'score_text', 'violent_recid',\n",
       "       'priors_count', 'days_b_screening_arrest', 'c_jail_in', 'c_jail_out',\n",
       "       'c_case_number', 'c_days_from_compas', 'c_arrest_date',\n",
       "       'c_offense_date', 'c_charge_degree', 'c_charge_desc', 'is_recid',\n",
       "       'num_r_cases', 'r_case_number', 'r_charge_degree', 'r_days_from_arrest',\n",
       "       'r_offense_date', 'r_charge_desc', 'r_jail_in', 'r_jail_out',\n",
       "       'is_violent_recid', 'num_vr_cases', 'vr_case_number',\n",
       "       'vr_charge_degree', 'vr_offense_date', 'vr_charge_desc', 'release',\n",
       "       'sex_1_male', 'African_American', 'Asian', 'Caucasian', 'Hispanic',\n",
       "       'Native_American', 'race_Other', 'Greater_45', '25_45', 'Less_25'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Split data into training & test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select out relevant data & generate the train and test data\n",
    "\n",
    "# train / test\n",
    "features = ['decile_score','Less_25','25_45','Greater_45','sex_1_male','African_American','Caucasian','is_violent_recid','juv_fel_count']\n",
    "X = data[features]\n",
    "y = data['release']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=120)\n",
    "\n",
    "risk_assess_train = X_train['decile_score']\n",
    "X_train = X_train.drop(['decile_score'],axis=1)\n",
    "\n",
    "risk_assess_test = X_test['decile_score'].tolist()\n",
    "X_test = X_test.drop(['decile_score'],axis=1)\n",
    "y_test = y_test.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables for analysis without penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_parameters = initialize_parameters(X_train,1,10)\n",
    "derivatives,grads = initialize_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B': array([[0.05137655],\n",
       "        [0.0579725 ],\n",
       "        [0.08133711],\n",
       "        [0.04825168],\n",
       "        [0.04528965],\n",
       "        [0.04435791],\n",
       "        [0.05091335],\n",
       "        [0.03454209]]),\n",
       " 'b': 8.195532851710617,\n",
       " 'q': 0.07918522106050441,\n",
       " 'sd_prior': 4.074323267341552,\n",
       " 'tau': 8}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Theta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-934ae806fd97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"sd_prior\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0minitial_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sd_prior'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"tau\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0minitial_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tau'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;34m\"Theta\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0minitial_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Theta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m      9\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Theta'"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"B\": initial_parameters['B'],\n",
    "    \"b\": initial_parameters['b'],\n",
    "    \"q\" : initial_parameters['q'],\n",
    "    \"sd_prior\" : initial_parameters['sd_prior'],\n",
    "    \"tau\" : initial_parameters['tau'],\n",
    "    \"Theta\" : initial_parameters['Theta']\n",
    "}\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.7057174836602743\n",
      "loss:  0.7057174936258401\n",
      "loss:  0.7057174986086334\n",
      "loss:  0.7057175011000185\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-bd345f2c223b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mmu_post\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_post_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_ra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0msd_post\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcalc_post_sd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_ra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mPhi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_Phi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_post\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msd_post\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_L\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPhi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Box/NYU_PostDoc/DecisionPrediction/Analysis/AnalysisPartFunctions.ipynb\u001b[0m in \u001b[0;36mcalc_Phi\u001b[0;34m(mu_post, sd_post, parameters)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;34m\"\\\\begin{equation}\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0;34m\"\\\\sigma_{post} = \\\\left \\\\{\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;34m\"\\t\\\\begin{array}{ll}\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;34m\"        \\\\sigma_{prior} \\\\cdot \\\\sqrt{\\\\frac{q}{q+1}} & if |\\\\mu_{ra} - \\\\mu_{prior}|<\\\\Theta \\\\\\\\\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Box/NYU_PostDoc/DecisionPrediction/Analysis/AnalysisPartFunctions.ipynb\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;34m\"\\\\begin{equation}\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0;34m\"\\\\sigma_{post} = \\\\left \\\\{\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;34m\"\\t\\\\begin{array}{ll}\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;34m\"        \\\\sigma_{prior} \\\\cdot \\\\sqrt{\\\\frac{q}{q+1}} & if |\\\\mu_{ra} - \\\\mu_{prior}|<\\\\Theta \\\\\\\\\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mcdf\u001b[0;34m(self, x, *args, **kwds)\u001b[0m\n\u001b[1;32m   1832\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# call only if at least 1 entry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1833\u001b[0m             \u001b[0mgoodargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margsreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1834\u001b[0;31m             \u001b[0mplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgoodargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1835\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1836\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = X_train\n",
    "Y = y_train.tolist()\n",
    "mu_ra = risk_assess_train.tolist()\n",
    "num_int = 10\n",
    "#learning_rate = 0.2\n",
    "Theta = list(range(0,1))\n",
    "\n",
    "# create containers for the optimized parameters for each \n",
    "param_info = {}\n",
    "for i in range(len(Theta)):\n",
    "    th = Theta[i]\n",
    "    param_info[th]={}\n",
    "    param_info[th]['auc']=[]\n",
    "    param_info[th]['loss']=[]\n",
    "    param_info[th]['learn_rate']=[]\n",
    "    param_info[th]['best_params']={}\n",
    "    param_info[th]['best_params']['B']=[0]*X.shape[1]\n",
    "    param_info[th]['best_params']['b']=0\n",
    "    param_info[th]['best_params']['q']=0\n",
    "    param_info[th]['best_params']['sd_prior']=0\n",
    "    param_info[th]['best_params']['tau']=0\n",
    "\n",
    "# learn model\n",
    "for theta in Theta: \n",
    "    \n",
    "    # reset the 'parameters' dict to the initial parameters values\n",
    "    parameters = {\"B\": initial_parameters['B'],\n",
    "                  \"b\": initial_parameters['b'],\n",
    "                  \"q\" : initial_parameters['q'],\n",
    "                  \"sd_prior\" : initial_parameters['sd_prior'],\n",
    "                  \"tau\" : initial_parameters['tau']}\n",
    "    \n",
    "    loss = []\n",
    "    learning_rate = []\n",
    "    j = 0\n",
    "    prev_L = 0 \n",
    "    init_lr = 0.001\n",
    "\n",
    "    #print(\"params: \",parameters)\n",
    "    \n",
    "    while j < num_int:\n",
    "        mu_prior = calc_prior_mean(X, parameters)\n",
    "        mu_post = calc_post_mean(mu_prior, mu_ra, parameters, theta)\n",
    "        sd_post =calc_post_sd(mu_prior, mu_ra, parameters, theta)\n",
    "        Phi = calc_Phi(mu_post, sd_post, parameters)\n",
    "        L = calc_L(Phi, Y)\n",
    "        loss.append(L)\n",
    "        \n",
    "        # set learning rate: if loss is negative double learning rate; else halve learning rate\n",
    "        if j==0:\n",
    "            lr=init_lr\n",
    "        elif j>0 and prev_L>L:\n",
    "            lr = lr*2\n",
    "        else:\n",
    "            lr = lr/2\n",
    "        \n",
    "        learning_rate.append(lr)\n",
    "        \n",
    "        derivatives = calc_component_derivs(X,parameters, derivatives, theta, mu_prior,mu_ra,mu_post,sd_post,Phi,Y)\n",
    "        grads = calc_gradients(X,grads,derivatives)\n",
    "        parameters = update_parameters(parameters, grads, lr)\n",
    "        prev_L = L\n",
    "        #print(\"intermediate params: \",parameters)\n",
    "        \n",
    "        # print loss so we can track the progress of the model\n",
    "        if j%1==0:\n",
    "            print(\"loss: \",L)\n",
    "        j+=1\n",
    "    \n",
    "    param_info[theta]['loss'] = loss\n",
    "    param_info[theta]['learn_rate'] = learning_rate\n",
    "    #print(\"optim params: \", parameters)\n",
    "    \n",
    "    # test these parameters to calculate auc and compare to others\n",
    "    Phi_test = predict_choice(X_test,risk_assess_test,parameters,theta)\n",
    "    \n",
    "    # calculate the auc with the converged weights\n",
    "    auc = roc_auc_score(y_test,Phi_test)\n",
    "    param_info[theta]['auc'] = auc\n",
    "    #print(\"auc: \",auc)\n",
    "    \n",
    "    # if there is an improvement in the AUC, update the 'best_params' with those weights\n",
    "    param_info[theta]['best_params']['B'] = parameters['B']\n",
    "    param_info[theta]['best_params']['b'] = parameters['b']\n",
    "    param_info[theta]['best_params']['q'] = parameters['q']\n",
    "    param_info[theta]['best_params']['sd_prior'] = parameters['sd_prior']\n",
    "    param_info[theta]['best_params']['tau'] = parameters['tau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in param_info:\n",
    "    print(\"Theta = \",i)\n",
    "    print(param_info[i]['best_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "colors = cm.rainbow(np.linspace(0, 1, len(range(0,10))))\n",
    "\n",
    "for i in param_info:\n",
    "    plt.plot(param_info[i]['best_params']['B'],'ro',color=colors[i],label='theta = %s' % (i))\n",
    "    plt.xlabel('B Coefficient')\n",
    "    plt.ylabel('Weight')\n",
    "    plt.legend(loc=\"upper right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = ['b','q','sd_prior','tau']\n",
    "for i in model_params:\n",
    "    for j in param_info:\n",
    "        plt.scatter(i, param_info[j]['best_params'][i])\n",
    "        plt.xlabel('Parameters')\n",
    "        plt.ylabel('Weights')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_theta = param_info[0]['best_params']\n",
    "each_theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in param_info:\n",
    "    plt.plot(param_info[i]['learn_rate'],label='theta = %s' % (i))\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot loss over theta\n",
    "for i in param_info:\n",
    "    plt.plot(param_info[i]['loss'],label='theta = %s' % (i))\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in param_info:\n",
    "    y_pred = predict_choice(X_test,risk_assess_test,param_info[i]['best_params'],best_theta=i)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f, theta = %s)' % (roc_auc,i))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC')\n",
    "    plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mu_post,bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "parameters = {'B': array([[0.07177631],\n",
    "        [0.07214579],\n",
    "        [0.02697002],\n",
    "        [0.03161949],\n",
    "        [0.02467784],\n",
    "        [0.03341922],\n",
    "        [0.07176589],\n",
    "        [0.08871475]]),\n",
    " 'b': 7.037519546355625,\n",
    " 'q': 0.30325946457835395,\n",
    " 'sd_prior': 3.313766807141957,\n",
    " 'tau': 9}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables for analysis with penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = initialize_parameters(X_test,1,10)\n",
    "derivatives,grads = initialize_dicts()\n",
    "\n",
    "X = X_train\n",
    "y = np.array(y_train)\n",
    "mu_ra = np.array(risk_assess_train)\n",
    "theta = 5\n",
    "num_int = 100\n",
    "learning_rate = 0.001\n",
    "k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = []\n",
    "j = 0\n",
    "\n",
    "while j < num_int:\n",
    "    \n",
    "    var_prior = parameters['var_prior'][0]\n",
    "    q = parameters['q'][0]\n",
    "    tau = parameters['tau']\n",
    "        \n",
    "    mu_prior = calc_prior_mean(X, parameters)[0]\n",
    "    mu_post = calc_post_mean(mu_prior, mu_ra, q, theta)\n",
    "    var_post = calc_post_var(mu_prior, mu_ra, var_prior, q, theta)\n",
    "    Phi = calc_Phi(mu_post, var_post, tau)\n",
    "    L = calc_L(Phi, y, mu_prior, k)\n",
    "    loss.append(np.sum(L))\n",
    "        \n",
    "    if j%%5==0:\n",
    "        print(L)\n",
    "        \n",
    "    derivatives = calc_component_derivs(X, y, parameters, derivatives, theta, mu_prior, mu_ra, mu_post, var_post, Phi, k)\n",
    "    grads = calc_gradients(grads, derivatives, mu_prior, X)\n",
    "    parameters = update_parameters(parameters, grads, learning_rate)\n",
    "    \n",
    "    j+=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = []\n",
    "\n",
    "var_prior = parameters['var_prior'][0]\n",
    "q = parameters['q'][0]\n",
    "tau = parameters['tau']\n",
    "\n",
    "mu_prior = calc_prior_mean(X, parameters)[0]\n",
    "mu_post = calc_post_mean(mu_prior, mu_ra, q, theta)\n",
    "var_post = calc_post_var(mu_prior, mu_ra, var_prior, q, theta)\n",
    "Phi = calc_Phi(mu_post, var_post, tau)\n",
    "L = calc_L(Phi, y, mu_prior, k)\n",
    "loss.append(np.sum(L))\n",
    "        \n",
    "derivatives = calc_component_derivs(X, y, parameters, derivatives, theta, mu_prior, mu_ra, mu_post, var_post, Phi, k)\n",
    "grads = calc_gradients(grads, derivatives, mu_prior, X)\n",
    "parameters = update_parameters(parameters, grads, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"B: \",parameters['B'])\n",
    "print(\"b: \",parameters['b'])\n",
    "print(\"q: \",parameters['q'])\n",
    "print(\"var_prior: \",parameters['var_prior'])\n",
    "print(\"tau: \",parameters['tau'])\n",
    "print(\"loss: \",loss)\n",
    "print(\"mu_prior: \",np.min(mu_prior),\"to\",np.max(mu_prior))\n",
    "print(\"mu_post: \",np.min(mu_post),\"to\",np.max(mu_post))\n",
    "print(\"Phi: \", np.min(Phi),\"to\",np.max(Phi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_prior = parameters['var_prior'][0]\n",
    "q = parameters['q'][0]\n",
    "tau = parameters['tau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_prior = calc_prior_mean(X, parameters)[0]\n",
    "mu_post = calc_post_mean(mu_prior, mu_ra, q, theta)\n",
    "var_post = calc_post_var(mu_prior, mu_ra, var_prior, q, theta)\n",
    "Phi = calc_Phi(mu_post, var_post, tau)\n",
    "L = calc_L(Phi, y, mu_prior, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = 10*((1-mu_prior)**3)\n",
    "test2 = y_train*np.log(1-Phi)+(1-y)*np.log(Phi)\n",
    "test = test1 + test2\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.append(np.sum(L))\n",
    "        \n",
    "derivatives = calc_component_derivs(X, y, parameters, derivatives, theta, mu_prior, mu_ra, mu_post, var_post, Phi, k)\n",
    "grads = calc_gradients(grads, derivatives, mu_prior, X)\n",
    "parameters = update_parameters(parameters, grads, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Predict test/train set examples \n",
    "#y_pred_train = predict(parameters,X_train,y_train,risk_assess_train,theta=5)\n",
    "#y_pred_test = predict(parameters,X_test,y_test,risk_assess_test,theta=5)\n",
    "\n",
    "# Print train/test Errors\n",
    "# general accuracy\n",
    "print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_pred_train - y_train)) * 100))\n",
    "print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_pred_test - y_test)) * 100))\n",
    "\n",
    "# confusion matrix\n",
    "confmat = []\n",
    "\n",
    "for true,pred in zip(y_train,y_pred_train):\n",
    "    if(true==1 and pred==1):\n",
    "        confmat.append(\"tp\")\n",
    "    elif(true==1 and pred==0):\n",
    "        confmat.append(\"fn\")\n",
    "    elif(true==0 and pred==0):\n",
    "        confmat.append(\"tn\")\n",
    "    else:\n",
    "        confmat.append(fp)\n",
    "\n",
    "print(\"true positives: \",confmat.count('tp'))\n",
    "print(\"false positives: \",confmat.count('fp'))\n",
    "print(\"true negatives: \",confmat.count('tn'))\n",
    "print(\"false negatives: \",confmat.count('fn'))\n",
    "\n",
    "if (confmat.count('tp')+confmat.count('fn'))>0:\n",
    "    print(\"sensitivity/recall: \",confmat.count('tp')/(confmat.count('tp')+confmat.count('fn')))\n",
    "else:\n",
    "    print(\"sensitivity/recall: N/A\")\n",
    "    \n",
    "if (confmat.count('tn')+confmat.count('fp'))>0:\n",
    "    print(\"specificity: \",confmat.count('tn')/(confmat.count('tn')+confmat.count('fp')))\n",
    "else:\n",
    "    print(\"specificity: N/A\")\n",
    "    \n",
    "if (confmat.count('tp')+confmat.count('fp'))>0:\n",
    "    print(\"precision: \",confmat.count('tp')/(confmat.count('tp')+confmat.count('fp')))\n",
    "else:\n",
    "    print(\"precision: N/A\")\n",
    "    \n",
    "model_dict = {\"nLL\": L,\n",
    "              \"y_pred_test\": y_pred_test,\n",
    "              \"y_pred_train\" : y_pred_train,\n",
    "              \"parameters\" : parameters\n",
    "              \"learning_rate\" : learning_rate,\n",
    "              \"num_iterations\": num_iterations}\n",
    "\n",
    "#return model_dict\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(X,y,parameters,mu_ra,theta,num_int,learning_rate,k):\n",
    "    \n",
    "    mu_ra = np.array(mu_ra)\n",
    "    y=np.array(y)\n",
    "    loss = []\n",
    "    j = 0\n",
    "    \n",
    "    while j < num_int:\n",
    "        \n",
    "        var_prior = parameters['var_prior'][0]\n",
    "        q = parameters['q'][0]\n",
    "        tau = parameters['tau']\n",
    "        \n",
    "        mu_prior = calc_prior_mean(X, parameters)[0]\n",
    "        mu_post = calc_post_mean(mu_prior, mu_ra, q, theta)\n",
    "        var_post = calc_post_var(mu_prior, mu_ra, var_prior, q, theta)\n",
    "        Phi = calc_Phi(mu_post, var_post, tau)\n",
    "        L = calc_L(Phi, y, mu_prior, k)\n",
    "        loss.append(np.sum(L))\n",
    "        \n",
    "        derivatives = calc_component_derivs(X, parameters, theta, mu_prior, mu_ra, mu_post, var_post, Phi, k)\n",
    "        grads = calc_gradients(derivatives, mu_prior, X)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        #print(parameters)\n",
    "        j+=1\n",
    "        \n",
    "    return loss, parameters, derivatives, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters,X,y,risk_assess,theta):\n",
    "    \n",
    "    tau = parameters['tau']\n",
    "    q = parameters['q']\n",
    "    mu_ra = np.array(risk_assess)\n",
    "    mu_prior = calc_prior_mean(X,parameters)[0]\n",
    "    var_prior = parameters['var_prior']\n",
    "    #var_ra = calc_var_ra(var_prior,mu_prior,mu_ra,q,theta)\n",
    "    \n",
    "    mu_post = calc_post_mean(mu_prior, mu_ra, q, theta)\n",
    "    var_post = calc_post_var(mu_prior, mu_ra, var_prior, q, theta)\n",
    "    Phi = calc_Phi(mu_post,var_post,tau)\n",
    "    #L = calc_L(Phi,y)\n",
    "    \n",
    "    y_pred = [1 if Phi[i]>0.5 else 0 for i in range(len(Phi))]\n",
    "    \n",
    "    return y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from ipynb.fs.full.GenerateData import generatedata\n",
    "from ipynb.fs.full.AnalysisPartFunctions import initialize_parameters,initialize_dicts,calc_prior_mean,calc_post_mean,calc_post_sd,calc_Phi,calc_L,calc_component_derivs,calc_gradients,update_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Generate data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(generatedata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>...</th>\n",
       "      <th>r_charge_desc</th>\n",
       "      <th>r_jail_in</th>\n",
       "      <th>r_jail_out</th>\n",
       "      <th>is_violent_recid</th>\n",
       "      <th>num_vr_cases</th>\n",
       "      <th>vr_case_number</th>\n",
       "      <th>vr_charge_degree</th>\n",
       "      <th>vr_offense_date</th>\n",
       "      <th>vr_charge_desc</th>\n",
       "      <th>release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>miguel hernandez</td>\n",
       "      <td>miguel</td>\n",
       "      <td>hernandez</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other</td>\n",
       "      <td>1947-04-18 00:00:00.000000</td>\n",
       "      <td>69</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>michael ryan</td>\n",
       "      <td>michael</td>\n",
       "      <td>ryan</td>\n",
       "      <td>Male</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>1985-02-06 00:00:00.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>kevon dixon</td>\n",
       "      <td>kevon</td>\n",
       "      <td>dixon</td>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1982-01-22 00:00:00.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>...</td>\n",
       "      <td>Felony Battery (Dom Strang)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13009779CF10A</td>\n",
       "      <td>(F3)</td>\n",
       "      <td>2013-07-05 00:00:00.000000</td>\n",
       "      <td>Felony Battery (Dom Strang)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>ed philo</td>\n",
       "      <td>ed</td>\n",
       "      <td>philo</td>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1991-05-14 00:00:00.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>...</td>\n",
       "      <td>Driving Under The Influence</td>\n",
       "      <td>2013-06-16 09:05:47.000000</td>\n",
       "      <td>2013-06-16 07:18:55.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>marcu brown</td>\n",
       "      <td>marcu</td>\n",
       "      <td>brown</td>\n",
       "      <td>Male</td>\n",
       "      <td>African-American</td>\n",
       "      <td>1993-01-21 00:00:00.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  id              name    first       last   sex              race  \\\n",
       "0      0   1  miguel hernandez   miguel  hernandez  Male             Other   \n",
       "1      1   2      michael ryan  michael       ryan  Male         Caucasian   \n",
       "2      2   3       kevon dixon    kevon      dixon  Male  African-American   \n",
       "3      3   4          ed philo       ed      philo  Male  African-American   \n",
       "4      4   5       marcu brown    marcu      brown  Male  African-American   \n",
       "\n",
       "                          dob  age          age_cat  ...  \\\n",
       "0  1947-04-18 00:00:00.000000   69  Greater than 45  ...   \n",
       "1  1985-02-06 00:00:00.000000   31          25 - 45  ...   \n",
       "2  1982-01-22 00:00:00.000000   34          25 - 45  ...   \n",
       "3  1991-05-14 00:00:00.000000   24     Less than 25  ...   \n",
       "4  1993-01-21 00:00:00.000000   23     Less than 25  ...   \n",
       "\n",
       "                 r_charge_desc                   r_jail_in  \\\n",
       "0                          NaN                         NaN   \n",
       "1                          NaN                         NaN   \n",
       "2  Felony Battery (Dom Strang)                         NaN   \n",
       "3  Driving Under The Influence  2013-06-16 09:05:47.000000   \n",
       "4                          NaN                         NaN   \n",
       "\n",
       "                   r_jail_out is_violent_recid  num_vr_cases  vr_case_number  \\\n",
       "0                         NaN                0           NaN             NaN   \n",
       "1                         NaN                0           NaN             NaN   \n",
       "2                         NaN                1           NaN   13009779CF10A   \n",
       "3  2013-06-16 07:18:55.000000                0           NaN             NaN   \n",
       "4                         NaN                0           NaN             NaN   \n",
       "\n",
       "   vr_charge_degree             vr_offense_date               vr_charge_desc  \\\n",
       "0               NaN                         NaN                          NaN   \n",
       "1               NaN                         NaN                          NaN   \n",
       "2              (F3)  2013-07-05 00:00:00.000000  Felony Battery (Dom Strang)   \n",
       "3               NaN                         NaN                          NaN   \n",
       "4               NaN                         NaN                          NaN   \n",
       "\n",
       "  release  \n",
       "0       1  \n",
       "1       0  \n",
       "2       1  \n",
       "3       1  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check how many released/remanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6715\n",
       "0    5027\n",
       "Name: release, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.release.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Create dummy variables for categorical variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_dummies = pd.get_dummies(data['sex'])\n",
    "race_dummies = pd.get_dummies(data['race'])\n",
    "\n",
    "data['sex_1_male'] = sex_dummies['Male']\n",
    "data['African_American']=race_dummies['African-American']\n",
    "data['Asian']=race_dummies['Asian']\n",
    "data['Caucasian']=race_dummies['Caucasian']\n",
    "data['Hispanic'] = race_dummies['Hispanic']\n",
    "data['Native_American']=race_dummies['Native American']\n",
    "data['Other']=race_dummies['Other']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c) Split data into training & test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select out relevant data & generate the train and test data\n",
    "\n",
    "# train / test\n",
    "X = data[['release','decile_score','age']].drop(['release'],axis=1)#,'is_violent_recid'\n",
    "y = data['release']\n",
    "class_names = data.release.unique()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=120)\n",
    "\n",
    "risk_assess_train = X_train['decile_score']\n",
    "X_train = X_train.drop(['decile_score'],axis=1)\n",
    "\n",
    "risk_assess_test = X_test['decile_score']\n",
    "X_test = X_test.drop(['decile_score'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables for analysis without penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train['age'].tolist()\n",
    "Y = y_train.tolist()\n",
    "mu_ra = risk_assess_train.tolist()\n",
    "theta = 5\n",
    "num_int = 10\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = initialize_parameters(X_train,1,10)\n",
    "#parameters = {\n",
    "#    'B':0.023820856984315887,\n",
    "#    'b': 5.404939356823157,\n",
    "#    'q': 0.7178027471079145,\n",
    "#    'sd_prior': 4.786505876750552,\n",
    "#    'tau': 9\n",
    "#}\n",
    "derivatives,grads = initialize_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B': 0.015812910378652678,\n",
       " 'b': 6.960580130229113,\n",
       " 'q': 0.9259321407179847,\n",
       " 'sd_prior': 4.532735652988392,\n",
       " 'tau': 9}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86224928422804\n",
      "0.8622243479545831\n",
      "0.8621994181004942\n",
      "0.8621744946659577\n",
      "0.8621495776511194\n",
      "0.8621246670561357\n",
      "0.8620997628812259\n",
      "0.8620748651265343\n",
      "0.8620499737922276\n",
      "0.8620250888784606\n"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "j = 0\n",
    "\n",
    "while j < num_int:\n",
    "    \n",
    "    #var_prior = parameters['var_prior']\n",
    "    #q = parameters['q']\n",
    "    #tau = parameters['tau']\n",
    "        \n",
    "    mu_prior = calc_prior_mean(X, parameters)\n",
    "    mu_post = calc_post_mean(mu_prior, mu_ra, parameters, theta)\n",
    "    sd_post =calc_post_sd(mu_prior, mu_ra, parameters, theta)\n",
    "    Phi = calc_Phi(mu_post, sd_post, parameters)\n",
    "    L = calc_L(Phi, Y)\n",
    "    loss.append(L)\n",
    "        \n",
    "    derivatives = calc_component_derivs(X,parameters, derivatives, theta, mu_prior,mu_ra,mu_post,sd_post,Phi,Y)\n",
    "    grads = calc_gradients(X,grads,derivatives)\n",
    "    parameters = update_parameters(parameters, grads, learning_rate)\n",
    "       \n",
    "    if j%1==0:\n",
    "        print(L)\n",
    "        #plt.plot(loss)\n",
    "    j+=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fee45732050>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mu_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mu_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables for analysis with penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = initialize_parameters(X_test,1,10)\n",
    "derivatives,grads = initialize_dicts()\n",
    "\n",
    "X = X_train\n",
    "y = np.array(y_train)\n",
    "mu_ra = np.array(risk_assess_train)\n",
    "theta = 5\n",
    "num_int = 100\n",
    "learning_rate = 0.001\n",
    "k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = []\n",
    "j = 0\n",
    "\n",
    "while j < num_int:\n",
    "    \n",
    "    var_prior = parameters['var_prior'][0]\n",
    "    q = parameters['q'][0]\n",
    "    tau = parameters['tau']\n",
    "        \n",
    "    mu_prior = calc_prior_mean(X, parameters)[0]\n",
    "    mu_post = calc_post_mean(mu_prior, mu_ra, q, theta)\n",
    "    var_post = calc_post_var(mu_prior, mu_ra, var_prior, q, theta)\n",
    "    Phi = calc_Phi(mu_post, var_post, tau)\n",
    "    L = calc_L(Phi, y, mu_prior, k)\n",
    "    loss.append(np.sum(L))\n",
    "        \n",
    "    if j%%5==0:\n",
    "        print(L)\n",
    "        \n",
    "    derivatives = calc_component_derivs(X, y, parameters, derivatives, theta, mu_prior, mu_ra, mu_post, var_post, Phi, k)\n",
    "    grads = calc_gradients(grads, derivatives, mu_prior, X)\n",
    "    parameters = update_parameters(parameters, grads, learning_rate)\n",
    "    \n",
    "    j+=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = []\n",
    "\n",
    "var_prior = parameters['var_prior'][0]\n",
    "q = parameters['q'][0]\n",
    "tau = parameters['tau']\n",
    "\n",
    "mu_prior = calc_prior_mean(X, parameters)[0]\n",
    "mu_post = calc_post_mean(mu_prior, mu_ra, q, theta)\n",
    "var_post = calc_post_var(mu_prior, mu_ra, var_prior, q, theta)\n",
    "Phi = calc_Phi(mu_post, var_post, tau)\n",
    "L = calc_L(Phi, y, mu_prior, k)\n",
    "loss.append(np.sum(L))\n",
    "        \n",
    "derivatives = calc_component_derivs(X, y, parameters, derivatives, theta, mu_prior, mu_ra, mu_post, var_post, Phi, k)\n",
    "grads = calc_gradients(grads, derivatives, mu_prior, X)\n",
    "parameters = update_parameters(parameters, grads, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"B: \",parameters['B'])\n",
    "print(\"b: \",parameters['b'])\n",
    "print(\"q: \",parameters['q'])\n",
    "print(\"var_prior: \",parameters['var_prior'])\n",
    "print(\"tau: \",parameters['tau'])\n",
    "print(\"loss: \",loss)\n",
    "print(\"mu_prior: \",np.min(mu_prior),\"to\",np.max(mu_prior))\n",
    "print(\"mu_post: \",np.min(mu_post),\"to\",np.max(mu_post))\n",
    "print(\"Phi: \", np.min(Phi),\"to\",np.max(Phi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_prior = parameters['var_prior'][0]\n",
    "q = parameters['q'][0]\n",
    "tau = parameters['tau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_prior = calc_prior_mean(X, parameters)[0]\n",
    "mu_post = calc_post_mean(mu_prior, mu_ra, q, theta)\n",
    "var_post = calc_post_var(mu_prior, mu_ra, var_prior, q, theta)\n",
    "Phi = calc_Phi(mu_post, var_post, tau)\n",
    "L = calc_L(Phi, y, mu_prior, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = 10*((1-mu_prior)**3)\n",
    "test2 = y_train*np.log(1-Phi)+(1-y)*np.log(Phi)\n",
    "test = test1 + test2\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.append(np.sum(L))\n",
    "        \n",
    "derivatives = calc_component_derivs(X, y, parameters, derivatives, theta, mu_prior, mu_ra, mu_post, var_post, Phi, k)\n",
    "grads = calc_gradients(grads, derivatives, mu_prior, X)\n",
    "parameters = update_parameters(parameters, grads, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Predict test/train set examples \n",
    "#y_pred_train = predict(parameters,X_train,y_train,risk_assess_train,theta=5)\n",
    "#y_pred_test = predict(parameters,X_test,y_test,risk_assess_test,theta=5)\n",
    "\n",
    "# Print train/test Errors\n",
    "# general accuracy\n",
    "print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_pred_train - y_train)) * 100))\n",
    "print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_pred_test - y_test)) * 100))\n",
    "\n",
    "# confusion matrix\n",
    "confmat = []\n",
    "\n",
    "for true,pred in zip(y_train,y_pred_train):\n",
    "    if(true==1 and pred==1):\n",
    "        confmat.append(\"tp\")\n",
    "    elif(true==1 and pred==0):\n",
    "        confmat.append(\"fn\")\n",
    "    elif(true==0 and pred==0):\n",
    "        confmat.append(\"tn\")\n",
    "    else:\n",
    "        confmat.append(fp)\n",
    "\n",
    "print(\"true positives: \",confmat.count('tp'))\n",
    "print(\"false positives: \",confmat.count('fp'))\n",
    "print(\"true negatives: \",confmat.count('tn'))\n",
    "print(\"false negatives: \",confmat.count('fn'))\n",
    "\n",
    "if (confmat.count('tp')+confmat.count('fn'))>0:\n",
    "    print(\"sensitivity/recall: \",confmat.count('tp')/(confmat.count('tp')+confmat.count('fn')))\n",
    "else:\n",
    "    print(\"sensitivity/recall: N/A\")\n",
    "    \n",
    "if (confmat.count('tn')+confmat.count('fp'))>0:\n",
    "    print(\"specificity: \",confmat.count('tn')/(confmat.count('tn')+confmat.count('fp')))\n",
    "else:\n",
    "    print(\"specificity: N/A\")\n",
    "    \n",
    "if (confmat.count('tp')+confmat.count('fp'))>0:\n",
    "    print(\"precision: \",confmat.count('tp')/(confmat.count('tp')+confmat.count('fp')))\n",
    "else:\n",
    "    print(\"precision: N/A\")\n",
    "    \n",
    "model_dict = {\"nLL\": L,\n",
    "              \"y_pred_test\": y_pred_test,\n",
    "              \"y_pred_train\" : y_pred_train,\n",
    "              \"parameters\" : parameters\n",
    "              \"learning_rate\" : learning_rate,\n",
    "              \"num_iterations\": num_iterations}\n",
    "\n",
    "#return model_dict\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(X,y,parameters,mu_ra,theta,num_int,learning_rate,k):\n",
    "    \n",
    "    mu_ra = np.array(mu_ra)\n",
    "    y=np.array(y)\n",
    "    loss = []\n",
    "    j = 0\n",
    "    \n",
    "    while j < num_int:\n",
    "        \n",
    "        var_prior = parameters['var_prior'][0]\n",
    "        q = parameters['q'][0]\n",
    "        tau = parameters['tau']\n",
    "        \n",
    "        mu_prior = calc_prior_mean(X, parameters)[0]\n",
    "        mu_post = calc_post_mean(mu_prior, mu_ra, q, theta)\n",
    "        var_post = calc_post_var(mu_prior, mu_ra, var_prior, q, theta)\n",
    "        Phi = calc_Phi(mu_post, var_post, tau)\n",
    "        L = calc_L(Phi, y, mu_prior, k)\n",
    "        loss.append(np.sum(L))\n",
    "        \n",
    "        derivatives = calc_component_derivs(X, parameters, theta, mu_prior, mu_ra, mu_post, var_post, Phi, k)\n",
    "        grads = calc_gradients(derivatives, mu_prior, X)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        #print(parameters)\n",
    "        j+=1\n",
    "        \n",
    "    return loss, parameters, derivatives, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters,X,y,risk_assess,theta):\n",
    "    \n",
    "    tau = parameters['tau']\n",
    "    q = parameters['q']\n",
    "    mu_ra = np.array(risk_assess)\n",
    "    mu_prior = calc_prior_mean(X,parameters)[0]\n",
    "    var_prior = parameters['var_prior']\n",
    "    #var_ra = calc_var_ra(var_prior,mu_prior,mu_ra,q,theta)\n",
    "    \n",
    "    mu_post = calc_post_mean(mu_prior, mu_ra, q, theta)\n",
    "    var_post = calc_post_var(mu_prior, mu_ra, var_prior, q, theta)\n",
    "    Phi = calc_Phi(mu_post,var_post,tau)\n",
    "    #L = calc_L(Phi,y)\n",
    "    \n",
    "    y_pred = [1 if Phi[i]>0.5 else 0 for i in range(len(Phi))]\n",
    "    \n",
    "    return y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
